{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2d052d-90c7-4723-9456-61017f76ab6a",
   "metadata": {},
   "source": [
    "# Full Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669357fb-b74b-4fac-a018-924159113dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c79984c-b2f3-4ab7-9334-800bf931129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6d5fd-8826-4043-8064-2211edff7c53",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a02e166-78d9-4292-a519-7bac2bebe01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load candidates\n",
    "with open('data/wordle-candidates.json', 'r') as file:\n",
    "    wordle_candidates = json.load(file)\n",
    "\n",
    "# Load answers\n",
    "with open('data/wordle-answers.json', 'r') as file:\n",
    "    wordle_answers = json.load(file)\n",
    "\n",
    "wordle_candidates = pd.DataFrame(wordle_candidates['words'], columns=['word'])\n",
    "wordle_answers = pd.DataFrame(wordle_answers['words'], columns=['word'])\n",
    "wordle_candidates['is_answer'] = 0\n",
    "wordle_answers['is_answer'] = 1\n",
    "wordle = wordle_candidates.append(wordle_answers).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ad3da7-40f1-4122-811c-9fd5bf2be0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all words\n",
    "words_all = pd.read_table('data/archive/en_words_1_5-5.txt', delimiter=' ', header=None, index_col=None,\n",
    "                         names=['word_len', 'word_freq', 'n_articles']).reset_index()\n",
    "words_all = words_all.rename(columns={'index': 'word'})\n",
    "\n",
    "# Filter by english\n",
    "alphabet = list('abcdefghijklmnopqrstuvwxyz')\n",
    "words_all = words_all.loc[words_all.word.apply(lambda x: all([l in alphabet for l in x]))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d00cb0-06d1-4c68-bfeb-343622904630",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4cf8e6-7c7d-44d7-9a8b-d1848af67039",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_dict = {l: i for i, l in enumerate(list('abcdefghijklmnopqrstuvwxyz'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c4520c3-aae9-4e40-9594-0dc58547ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise solutions vector\n",
    "solutions = np.zeros((wordle_answers.shape[0], 26, 5), dtype='int8')\n",
    "for i, word in enumerate(wordle_answers.word):\n",
    "    for j, l in enumerate(word):\n",
    "        solutions[i, alpha_dict[l], j] = 1\n",
    "        \n",
    "        \n",
    "# Initialise candidates vector\n",
    "candidates = np.zeros((wordle.shape[0], 26, 5), dtype='int8')\n",
    "for i, word in enumerate(wordle.word):\n",
    "    for j, l in enumerate(word):\n",
    "        candidates[i, alpha_dict[l], j] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61312c7b-3c7d-4de2-bef9-bdd1a86a530d",
   "metadata": {},
   "source": [
    "## Game Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c9780e-fad7-469c-adfd-bbb712433f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback(input_word, solution):\n",
    "    output = ''\n",
    "    for i in range(5):\n",
    "        if input_word[i] == solution[i]:\n",
    "            output += 'G'\n",
    "        elif input_word[i] in solution:\n",
    "            output += 'Y'\n",
    "        else:\n",
    "            output += 'X'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac3a9ba-4058-4cc4-919c-f928d86262e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wordset(input_word, feedback, wordset):\n",
    "    newset = wordset.copy()\n",
    "    for i in range(5):\n",
    "        if feedback[i] == 'G':\n",
    "            newset = newset.loc[newset.word.str[i] == input_word[i]]\n",
    "        elif feedback[i] == 'Y':\n",
    "            newset = newset.loc[newset.word.str.contains(input_word[i]) & newset.word.apply(lambda x: x[i] != input_word[i])]\n",
    "        else:\n",
    "            newset = newset.loc[~newset.word.str.contains(input_word[i])]\n",
    "    return newset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede6405-5d68-4bd1-a618-a3e162fefc4f",
   "metadata": {},
   "source": [
    "## Vector Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8ba45f-68d1-4acd-bf6c-d4eb4119312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vec(word):\n",
    "    mat = np.zeros((26, 5))\n",
    "    for i, l in enumerate(word):\n",
    "        mat[alpha_dict[l], i] = 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa8c313-702b-45ed-93c2-4cebf13a0d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(word, mask):\n",
    "    word_vec = init_vec(word)\n",
    "    solutions_masked = solutions[mask]\n",
    "    greens = solutions_masked * word_vec\n",
    "    yellows = word_vec * (\n",
    "        (solutions_masked.sum(axis=2) >= word_vec.sum(axis=1)) & \n",
    "        (word_vec.sum(axis=1) > 0)) \\\n",
    "        .reshape(np.sum(mask), 26, 1) - greens\n",
    "    greys = word_vec - greens - yellows\n",
    "    scores = np.array([np.sum(greens, axis=(1,2)), np.sum(yellows, axis=(1,2)), np.sum(greys, axis=(1,2))]).T\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c1f2dc-2501-4f94-8d94-c815ae338913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_scores(word, mask):\n",
    "    scores = get_scores(word, mask)\n",
    "    df_scores = pd.DataFrame(scores, columns=['g', 'y', 'x'])\n",
    "    df_scores['score'] = df_scores.g * 2 + df_scores.y\n",
    "    \n",
    "    return df_scores.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c461649a-df4b-42e0-af44-7b37f4ea5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_cands(word, filter_mask, candidate_mask):\n",
    "    return np.sum((np.sum((filter_mask * solutions[candidate_mask]) == solutions[candidate_mask], axis=(-2,-1)) == 130))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54655ee6-36ab-4959-bcc0-da9c652ff016",
   "metadata": {},
   "source": [
    "### Filter Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d363dc42-9550-4ed8-9de7-1accdcd69740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_candidate_mask():\n",
    "    return np.array([True] * wordle.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa7e409-9c10-4cee-b579-11b0ff3bebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_filter_mask():\n",
    "    filter_mask = np.ones((26,5))\n",
    "    return filter_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44e5a680-efd1-43de-b603-f238c07264a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_filter_mask(input_word, feedback, mask):\n",
    "    wv = init_vec(input_word)\n",
    "    row_idx = [alpha_dict[l] for l in input_word]\n",
    "    output = mask.copy()\n",
    "    for i, (fb, r) in enumerate(zip(feedback, row_idx)):\n",
    "        # Green\n",
    "        if fb == 'G':\n",
    "            output[:, i] = 0\n",
    "            output[r, i] = 1\n",
    "        # Yellow\n",
    "        elif fb == 'Y':\n",
    "            output[r, i] = 0\n",
    "        # Grey\n",
    "        elif fb == 'X':\n",
    "            output[r, :] = 0\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13475a2a-7f28-4d39-be49-f69abc15cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_candidate_mask(input_word, feedback, wordset, mask):\n",
    "    newmask = mask.copy()\n",
    "    for i in range(5):\n",
    "        if feedback[i] == 'G':\n",
    "            newmask[~wordset.word.str[i].eq(input_word[i])] = False\n",
    "        elif feedback[i] == 'Y':\n",
    "            newmask[~(wordset.word.str.contains(input_word[i]) & wordset.word.apply(lambda x: x[i] != input_word[i]))] = False\n",
    "        elif feedback[i] == 'X':\n",
    "            newmask[wordset.word.str.contains(input_word[i])] = False\n",
    "            \n",
    "    return newmask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518b43e-0e6a-4d24-a7e6-0d7369ef944d",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84587a4-e4f4-4af1-989e-3df28d8d4e00",
   "metadata": {},
   "source": [
    "### Function to Generate G/Y/X Counts\n",
    "```py\n",
    "# Compute greens, yellows, and greys\n",
    "greens = candidates * word_vec\n",
    "yellows = word_vec * (\n",
    "    (candidates.sum(axis=2) >= word_vec.sum(axis=1)) & \n",
    "    (word_vec.sum(axis=1) > 0)) \\\n",
    "    .reshape(12972, 26, 1) - greens\n",
    "greys = word_vec - greens - yellows\n",
    "\n",
    "# Set up GYX tensor\n",
    "gyx_reshaped = np.stack([greens, yellows, greys], axis=1)\n",
    "gyx_reshaped = gyx_reshaped.reshape(12972, 390)\n",
    "\n",
    "# Compute raw candidate data\n",
    "ncands = np.apply_along_axis(compute_cands, 1, gyx_reshaped)\n",
    "ncands_max = np.max(ncands)\n",
    "ncands_mean = np.mean(ncands)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42a28026-f439-40e5-b8af-eade431b9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_word = 'saine'\n",
    "iv = init_vec(input_word)\n",
    "iv_tensor = tf.constant(iv, dtype='int8')\n",
    "candidates_tensor = tf.constant(candidates, dtype='int8')\n",
    "solutions_tensor = tf.constant(solutions, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "747fd677-c2f0-4738-af63-e95ee97232f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green locations\n",
    "greens_tensor = iv_tensor * candidates_tensor\n",
    "\n",
    "# Yellow locations\n",
    "yellows_tensor = iv_tensor * (\n",
    "    tf.reshape(\n",
    "        tf.math.multiply(\n",
    "            tf.cast(\n",
    "                tf.math.greater_equal(tf.reduce_sum(candidates_tensor, axis=-1),tf.reduce_sum(iv_tensor, axis=-1)),\n",
    "                dtype='int8'\n",
    "            ),\n",
    "            tf.cast(\n",
    "                tf.math.greater(tf.reduce_sum(iv_tensor, axis=-1), 0),\n",
    "                dtype='int8'\n",
    "            )\n",
    "        ), shape=(12972, 26,1)\n",
    "    ) - \\\n",
    "    greens_tensor\n",
    ")\n",
    "\n",
    "# Grey locations\n",
    "greys_tensor = iv_tensor - greens_tensor - yellows_tensor\n",
    "\n",
    "# Set up tensor\n",
    "gyx_reshaped = tf.stack([greens_tensor, yellows_tensor, greys_tensor], axis=1)\n",
    "gyx_reshaped = tf.reshape(gyx_reshaped, (12972, 390))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52754172-1560-48d6-8120-d9caf6086f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check GYX against all solutions\n",
    "def compute_cands(gyx_triplet):\n",
    "    gyx = tf.reshape(gyx_triplet, (3, 26, 5))\n",
    "\n",
    "    # Green checks\n",
    "    green_boolean = tf.reduce_sum(\n",
    "        tf.cast((gyx[0] * solutions_tensor) == gyx[0], dtype='int8'),\n",
    "        axis=(-2,-1)\n",
    "    ) == 130\n",
    "\n",
    "    # Yellow avoid: All yellow locations are zero\n",
    "    yellow_avoid = tf.reduce_sum(\n",
    "        tf.cast(gyx[1] * solutions_tensor == 0, dtype='int8'),\n",
    "        axis=(-2, -1)\n",
    "    ) == 130\n",
    "\n",
    "    # Yellow present: \n",
    "    # 1. Compute row sums for yellow vector\n",
    "    # 2. Select rows with at least one yellow in each solution word vector\n",
    "    # 3. Compute row sums for solution vector to check there are at least one\n",
    "    # 4. Check that there are two\n",
    "    yellow_sums = tf.reduce_sum(gyx[1], axis=-1)\n",
    "    yellow_present = tf.reduce_sum(\n",
    "        tf.cast(tf.reduce_sum(\n",
    "            tf.cast(solutions[:, yellow_sums >= 1, :], dtype='int8'),\n",
    "            axis=-1\n",
    "        ) >= 1, dtype='int8'),\n",
    "        axis=-1\n",
    "    ) == 2\n",
    "\n",
    "    # Combine yellow checks\n",
    "    yellow_boolean = tf.math.logical_and(yellow_present, yellow_avoid)\n",
    "\n",
    "    # Grey checks\n",
    "    grey_boolean = tf.reduce_sum(\n",
    "        tf.cast(tf.reduce_sum(gyx[2], axis=-1, keepdims=True) * solutions == 0, dtype='int8'),\n",
    "        axis=(-2,-1)\n",
    "    ) == 130\n",
    "\n",
    "    # Count no. of candidates\n",
    "    green_boolean = tf.cast(green_boolean, dtype='int8')\n",
    "    yellow_boolean = tf.cast(yellow_boolean, dtype='int8')\n",
    "    grey_boolean = tf.cast(grey_boolean, dtype='int8')\n",
    "    combined_boolean = green_boolean * yellow_boolean * grey_boolean\n",
    "\n",
    "    return tf.reduce_sum(combined_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b93a6-2b52-4c39-8ce1-e758589aeafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch 0 - 0.12418174743652344\n",
      "Running batch 10 - 20.804954767227173\n",
      "Running batch 20 - 44.57127046585083\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "gyx_dataset = tf.data.Dataset.from_tensor_slices(gyx_reshaped)\n",
    "batched_gyx = gyx_dataset.batch(100)\n",
    "ncands = []\n",
    "counter = 0\n",
    "for batch in batched_gyx:\n",
    "    if counter % 10 == 0:\n",
    "        print(f'Running batch {counter} - {time.time()-t0}')\n",
    "    batch_ncands = [compute_cands(triplet) for triplet in batch]\n",
    "    ncands += batch_ncands\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c954fe7-1edd-4709-b994-604dce3e19f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch 0 - 0.010282278060913086\n",
      "Running batch 10 - 12.888877153396606\n",
      "Running batch 20 - 25.471890687942505\n",
      "Running batch 30 - 38.16497611999512\n",
      "Running batch 40 - 50.7547082901001\n",
      "Running batch 50 - 63.46690559387207\n",
      "Running batch 60 - 76.18823003768921\n",
      "Running batch 70 - 88.89395046234131\n",
      "Running batch 80 - 101.49941563606262\n",
      "Running batch 90 - 113.98473882675171\n",
      "Running batch 100 - 126.68144369125366\n",
      "Running batch 110 - 139.22911143302917\n",
      "Running batch 120 - 151.6520116329193\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "gyx_dataset = tf.data.Dataset.from_tensor_slices(gyx_reshaped)\n",
    "batched_gyx = gyx_dataset.batch(100)\n",
    "ncands = []\n",
    "counter = 0\n",
    "for batch in batched_gyx:\n",
    "    if counter % 10 == 0:\n",
    "        print(f'Running batch {counter} - {time.time()-t0}')\n",
    "    batch_ncands = [compute_cands(triplet) for triplet in batch]\n",
    "    ncands += batch_ncands\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d5f68f2-7a4b-42e0-b8a4-c3f16a20b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.039161270428615, 288)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ncands), np.max(ncands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93d8dd81-73fb-4479-b4d5-4b9e59b02103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.6>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.cast(ncands_tensor, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "434d028e-e772-4d1d-b482-618790293750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.6>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(tf.cast(ncands_tensor, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "072fcd10-e1f0-4b26-b219-1cb6b3bda80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch 0 - 0.0039823055267333984\n",
      "4.7484471797943115\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "scores = []\n",
    "batched_gyx = gyx_dataset.batch(100)\n",
    "counter = 0\n",
    "for batch in batched_gyx:\n",
    "    if counter % 10 == 0:\n",
    "        \n",
    "    scores_batch = [compute_gyx(x, solutions_subset_tensor) for x in batch]\n",
    "    scores += scores_batch\n",
    "    counter += 1\n",
    "    \n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "5128f0d9-966d-4974-ad6d-73ed09354df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "5263c79c-8d53-4799-afcd-5a6fdaf8c9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(26,), dtype=int32, numpy=\n",
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(greys_pos_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "b31d3298-44e3-4df1-be7a-eae70d5f6b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 26, 5), dtype=int32, numpy=\n",
       "array([[[1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 1]]], dtype=int32)>"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "840feaf0-35cb-4ee5-8de4-f43c2a501cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[2, 3]])>"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(tf.squeeze(tf.where(greens_pos_tensor==1)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "ef975b3d-172f-4d62-9b13-c2f9f0b9fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok: 2\n",
      "ok: 3\n"
     ]
    }
   ],
   "source": [
    "k=3\n",
    "greens_tensor = gyx_tensor[k][0]\n",
    "yellows_tensor = gyx_tensor[k][1]\n",
    "greys_tensor = gyx_tensor[k][2]    \n",
    "\n",
    "greens_pos_tensor = tf.reduce_sum(greens_tensor, axis=-2)\n",
    "yellows_pos_tensor = tf.reduce_sum(yellows_tensor, axis=-1)\n",
    "greys_pos_tensor = tf.reduce_sum(greys_tensor, axis=-1)\n",
    "\n",
    "global filter_mask_tensor\n",
    "filter_mask_tensor = tf.Variable(tf.ones((26,5), dtype='int32'))\n",
    "\n",
    "# Update greens\n",
    "green_totals = tf.squeeze(tf.where(greens_pos_tensor==1))\n",
    "for i in green_totals.numpy():\n",
    "    filter_mask_tensor = tf.cond(\n",
    "        tf.greater(i, 0),\n",
    "        lambda: filter_mask_tensor[:, i].assign(greens_tensor[:, i]),\n",
    "        lambda: filter_mask_tensor[: i]\n",
    "    )\n",
    "\n",
    "# Update yellows\n",
    "filter_mask_tensor = tf.cond(\n",
    "    tf.greater(tf.reduce_sum(yellows_pos_tensor), 0),\n",
    "    lambda: tf.Variable(tf.where(\n",
    "        tf.reshape(yellows_pos_tensor, (26, 1)) == 1, 0 + yellows_tensor, filter_mask_tensor\n",
    "    )),\n",
    "    lambda: filter_mask_tensor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "6b82089c-c857-446e-a74d-f6a69431738e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in green_totals.numpy():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "0f1524c0-f07c-450b-b0df-2a9ba0bbb8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(26,), dtype=int32, numpy=\n",
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greens_tensor[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3d6ee-e3c4-491a-b0cd-85bd1232c1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
