{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ecd6de6-b9cd-4e3a-b640-df0b132aba79",
   "metadata": {},
   "source": [
    "# Get Kaggle Kernel Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0959a27f-9ffe-42e8-8c4c-6a5b0e2f8660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/chrischow/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad366ab-cea9-450c-87ce-5cd5aeaa1a6d",
   "metadata": {},
   "source": [
    "## Connect to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ca0395-bfbf-41ff-8780-1f20a2762541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/chrischow/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f2de9-1c0e-42a9-9330-7c44a9931a79",
   "metadata": {},
   "source": [
    "## Get Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e39d75e3-11e0-47c8-85a0-aa5dd38efced",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['arles', 'arose', 'dares', 'lares', 'lores', 'nares',\n",
    "        'raile', 'raise', 'rales', 'rates', 'reais', 'roate',\n",
    "        'soare', 'tales', 'tares', 'tores']\n",
    "\n",
    "algos = ['lf', 'gyx', 'lf-pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f16b0f2d-dea7-410a-af4f-2bb94a0b27a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking lf-arles...Output already downloaded.\n",
      "Checking lf-arose...Output already downloaded.\n",
      "Checking lf-dares...Output already downloaded.\n",
      "Checking lf-lares...Output already downloaded.\n",
      "Checking lf-lores...Output already downloaded.\n",
      "Checking lf-nares...Output already downloaded.\n",
      "Checking lf-raile...Output already downloaded.\n",
      "Checking lf-raise...Output already downloaded.\n",
      "Checking lf-rales...Output already downloaded.\n",
      "Checking lf-rates...Output already downloaded.\n",
      "Checking lf-reais...Output already downloaded.\n",
      "Checking lf-roate...Output already downloaded.\n",
      "Checking lf-soare...Output already downloaded.\n",
      "Checking lf-tales...Output already downloaded.\n",
      "Checking lf-tares...Output already downloaded.\n",
      "Checking lf-tores...Output already downloaded.\n",
      "Checking lf-pop-arles...Downloaded output.\n",
      "Checking lf-pop-arose...Downloaded output.\n",
      "Checking lf-pop-dares...Downloaded output.\n",
      "Checking lf-pop-lares...Downloaded output.\n",
      "Checking lf-pop-lores...Downloaded output.\n",
      "Checking lf-pop-nares...Downloaded output.\n",
      "Checking lf-pop-raile...Downloaded output.\n",
      "Checking lf-pop-raise...Downloaded output.\n",
      "Checking lf-pop-rales...Downloaded output.\n",
      "Checking lf-pop-rates...Downloaded output.\n",
      "Checking lf-pop-reais...Downloaded output.\n",
      "Checking lf-pop-roate...Downloaded output.\n",
      "Checking lf-pop-soare...Downloaded output.\n",
      "Checking lf-pop-tales...Downloaded output.\n",
      "Checking lf-pop-tares...Downloaded output.\n",
      "Checking lf-pop-tores...Downloaded output.\n",
      "Checking gyx-arles...Output already downloaded.\n",
      "Checking gyx-arose...Output already downloaded.\n",
      "Checking gyx-dares...Output already downloaded.\n",
      "Checking gyx-lares...Output already downloaded.\n",
      "Checking gyx-lores...Output already downloaded.\n",
      "Checking gyx-nares...Output already downloaded.\n",
      "Checking gyx-raile...Output already downloaded.\n",
      "Checking gyx-raise...Output already downloaded.\n",
      "Checking gyx-rales...Output already downloaded.\n",
      "Checking gyx-rates...Output already downloaded.\n",
      "Checking gyx-reais...Output already downloaded.\n",
      "Checking gyx-roate...Output already downloaded.\n",
      "Checking gyx-soare...Output already downloaded.\n",
      "Checking gyx-tales...Output already downloaded.\n",
      "Checking gyx-tares...Output already downloaded.\n",
      "Checking gyx-tores...Output already downloaded.\n"
     ]
    }
   ],
   "source": [
    "for algo in algos:\n",
    "    for word in words:\n",
    "        kernel_ref = f'chrischow/wordlebot-{algo}-{word}'\n",
    "        download_path = f'./kernel_output/{algo}/'\n",
    "        filename = f\"wordlebot-{algo if algo != 'gyx' else 'expected_gyx'}-{word}.csv\"\n",
    "        print(f'Checking {algo}-{word}...', flush=True, end='')\n",
    "        if not filename in os.listdir(download_path):\n",
    "            if api.kernels_status(kernel_ref)['status'] == 'complete':\n",
    "                api.kernels_output(kernel_ref, path=download_path)\n",
    "                print('Downloaded output.')\n",
    "            else:\n",
    "                print('Kernel still running. Output not downloaded.')\n",
    "        else:\n",
    "            print('Output already downloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff493d4-86d3-4404-aae3-0663f6820bdf",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6130b212-f4a3-4a9c-b784-a95e62b28a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lf...\n",
      "Loading gyx...\n",
      "Loading lf-pop...\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for algo in algos:\n",
    "    print(f'Loading {algo}...')\n",
    "    for word in words:\n",
    "        download_path = f'./kernel_output/{algo}/'\n",
    "        if algo == 'gyx':\n",
    "            algo_correct = 'expected_gyx'\n",
    "        elif algo == 'lf-pop':\n",
    "            algo_correct = 'lf'\n",
    "        else:\n",
    "            algo_correct = algo\n",
    "        filename = f\"wordlebot-{algo_correct}-{word}.csv\"\n",
    "        \n",
    "        if filename in os.listdir(download_path):\n",
    "            temp_df = pd.read_csv(f'{download_path}{filename}')\n",
    "            with open(f\"{download_path}wordlebot-{algo}-{word}.log\") as f:\n",
    "                temp_log = f.readlines()\n",
    "            runtime = pd.DataFrame(eval(''.join(temp_log))).time.iloc[-1]\n",
    "            temp_results = pd.DataFrame([{\n",
    "                'Seed Word': word,\n",
    "                'Ranking Algorithm': algo,\n",
    "                'Runtime': runtime,\n",
    "                'Mean Steps': temp_df.steps.mean(),\n",
    "                'Success Rate': temp_df.steps.le(6).mean(),\n",
    "                '3-Steps or Less': temp_df.steps.le(3).mean(),\n",
    "                'Worst Case': temp_df.steps.max()\n",
    "            }])\n",
    "            \n",
    "            df = df.append(temp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69b394e5-17db-46c7-9df2-44f77b22320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['steps_rank'] = df['Mean Steps'].rank()\n",
    "df['success_rank'] = df['Success Rate'].rank(ascending=False)\n",
    "df['threestep_rank'] = df['3-Steps or Less'].rank(ascending=False)\n",
    "df['avg_rank'] = df[['steps_rank', 'success_rank', 'threestep_rank']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad179b8d-1e09-48ee-a7d6-3adf00847c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed Word</th>\n",
       "      <th>Ranking Algorithm</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Mean Steps</th>\n",
       "      <th>Success Rate</th>\n",
       "      <th>3-Steps or Less</th>\n",
       "      <th>Worst Case</th>\n",
       "      <th>steps_rank</th>\n",
       "      <th>success_rank</th>\n",
       "      <th>threestep_rank</th>\n",
       "      <th>avg_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tores</td>\n",
       "      <td>lf</td>\n",
       "      <td>232.967899</td>\n",
       "      <td>3.730022</td>\n",
       "      <td>0.991793</td>\n",
       "      <td>0.425054</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tores</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>326.544851</td>\n",
       "      <td>3.739957</td>\n",
       "      <td>0.993089</td>\n",
       "      <td>0.423758</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tares</td>\n",
       "      <td>lf</td>\n",
       "      <td>225.392809</td>\n",
       "      <td>3.739093</td>\n",
       "      <td>0.991793</td>\n",
       "      <td>0.419438</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tares</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>328.405781</td>\n",
       "      <td>3.750324</td>\n",
       "      <td>0.992657</td>\n",
       "      <td>0.419438</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tales</td>\n",
       "      <td>lf</td>\n",
       "      <td>233.820936</td>\n",
       "      <td>3.749028</td>\n",
       "      <td>0.994384</td>\n",
       "      <td>0.395680</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arose</td>\n",
       "      <td>lf</td>\n",
       "      <td>223.036801</td>\n",
       "      <td>3.739525</td>\n",
       "      <td>0.990065</td>\n",
       "      <td>0.429806</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arose</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>376.123500</td>\n",
       "      <td>3.748596</td>\n",
       "      <td>0.989201</td>\n",
       "      <td>0.430238</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raise</td>\n",
       "      <td>lf</td>\n",
       "      <td>232.002648</td>\n",
       "      <td>3.742549</td>\n",
       "      <td>0.988769</td>\n",
       "      <td>0.425054</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tales</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>278.706187</td>\n",
       "      <td>3.769762</td>\n",
       "      <td>0.993089</td>\n",
       "      <td>0.393521</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roate</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>290.981662</td>\n",
       "      <td>3.765875</td>\n",
       "      <td>0.990929</td>\n",
       "      <td>0.415551</td>\n",
       "      <td>9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roate</td>\n",
       "      <td>lf</td>\n",
       "      <td>196.688738</td>\n",
       "      <td>3.757235</td>\n",
       "      <td>0.990497</td>\n",
       "      <td>0.417279</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rales</td>\n",
       "      <td>lf</td>\n",
       "      <td>203.969526</td>\n",
       "      <td>3.784881</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.387905</td>\n",
       "      <td>8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raise</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>279.409335</td>\n",
       "      <td>3.754644</td>\n",
       "      <td>0.988337</td>\n",
       "      <td>0.422462</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rates</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>317.264952</td>\n",
       "      <td>3.790929</td>\n",
       "      <td>0.990929</td>\n",
       "      <td>0.403024</td>\n",
       "      <td>9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rates</td>\n",
       "      <td>lf</td>\n",
       "      <td>239.049976</td>\n",
       "      <td>3.776242</td>\n",
       "      <td>0.990497</td>\n",
       "      <td>0.404320</td>\n",
       "      <td>9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rales</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>315.789842</td>\n",
       "      <td>3.803888</td>\n",
       "      <td>0.993521</td>\n",
       "      <td>0.385313</td>\n",
       "      <td>8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raile</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>336.500517</td>\n",
       "      <td>3.769330</td>\n",
       "      <td>0.989201</td>\n",
       "      <td>0.416415</td>\n",
       "      <td>9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raile</td>\n",
       "      <td>lf</td>\n",
       "      <td>189.546732</td>\n",
       "      <td>3.758531</td>\n",
       "      <td>0.988337</td>\n",
       "      <td>0.418575</td>\n",
       "      <td>9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arles</td>\n",
       "      <td>lf</td>\n",
       "      <td>234.079909</td>\n",
       "      <td>3.798704</td>\n",
       "      <td>0.990929</td>\n",
       "      <td>0.388337</td>\n",
       "      <td>10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arles</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>346.197915</td>\n",
       "      <td>3.809935</td>\n",
       "      <td>0.991361</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>9</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nares</td>\n",
       "      <td>lf</td>\n",
       "      <td>238.601038</td>\n",
       "      <td>3.808207</td>\n",
       "      <td>0.991793</td>\n",
       "      <td>0.381857</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soare</td>\n",
       "      <td>lf</td>\n",
       "      <td>225.832832</td>\n",
       "      <td>3.783153</td>\n",
       "      <td>0.987473</td>\n",
       "      <td>0.403888</td>\n",
       "      <td>8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soare</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>278.151163</td>\n",
       "      <td>3.794384</td>\n",
       "      <td>0.987473</td>\n",
       "      <td>0.404752</td>\n",
       "      <td>8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reais</td>\n",
       "      <td>lf</td>\n",
       "      <td>204.245565</td>\n",
       "      <td>3.803024</td>\n",
       "      <td>0.988769</td>\n",
       "      <td>0.394816</td>\n",
       "      <td>9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nares</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>293.761462</td>\n",
       "      <td>3.822030</td>\n",
       "      <td>0.990929</td>\n",
       "      <td>0.382289</td>\n",
       "      <td>8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lares</td>\n",
       "      <td>lf</td>\n",
       "      <td>245.787240</td>\n",
       "      <td>3.809503</td>\n",
       "      <td>0.990065</td>\n",
       "      <td>0.384017</td>\n",
       "      <td>8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dares</td>\n",
       "      <td>lf</td>\n",
       "      <td>244.655717</td>\n",
       "      <td>3.816415</td>\n",
       "      <td>0.990929</td>\n",
       "      <td>0.369762</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dares</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>317.465164</td>\n",
       "      <td>3.828510</td>\n",
       "      <td>0.991361</td>\n",
       "      <td>0.368467</td>\n",
       "      <td>8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tales</td>\n",
       "      <td>gyx</td>\n",
       "      <td>11917.266150</td>\n",
       "      <td>3.836285</td>\n",
       "      <td>0.990929</td>\n",
       "      <td>0.371058</td>\n",
       "      <td>9</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lares</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>342.221368</td>\n",
       "      <td>3.826782</td>\n",
       "      <td>0.990497</td>\n",
       "      <td>0.380562</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reais</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>329.681257</td>\n",
       "      <td>3.825918</td>\n",
       "      <td>0.987041</td>\n",
       "      <td>0.393952</td>\n",
       "      <td>9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lores</td>\n",
       "      <td>lf</td>\n",
       "      <td>242.716667</td>\n",
       "      <td>3.846220</td>\n",
       "      <td>0.990929</td>\n",
       "      <td>0.367603</td>\n",
       "      <td>9</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>28.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lores</td>\n",
       "      <td>lf-pop</td>\n",
       "      <td>332.211099</td>\n",
       "      <td>3.854860</td>\n",
       "      <td>0.990497</td>\n",
       "      <td>0.367603</td>\n",
       "      <td>9</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>30.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roate</td>\n",
       "      <td>gyx</td>\n",
       "      <td>10169.933737</td>\n",
       "      <td>3.837149</td>\n",
       "      <td>0.985745</td>\n",
       "      <td>0.385745</td>\n",
       "      <td>9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tares</td>\n",
       "      <td>gyx</td>\n",
       "      <td>8236.806425</td>\n",
       "      <td>3.846652</td>\n",
       "      <td>0.988337</td>\n",
       "      <td>0.371490</td>\n",
       "      <td>9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arles</td>\n",
       "      <td>gyx</td>\n",
       "      <td>11323.127547</td>\n",
       "      <td>3.880346</td>\n",
       "      <td>0.989201</td>\n",
       "      <td>0.358099</td>\n",
       "      <td>8</td>\n",
       "      <td>38.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soare</td>\n",
       "      <td>gyx</td>\n",
       "      <td>10150.235974</td>\n",
       "      <td>3.857883</td>\n",
       "      <td>0.982721</td>\n",
       "      <td>0.381425</td>\n",
       "      <td>9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tores</td>\n",
       "      <td>gyx</td>\n",
       "      <td>11760.894683</td>\n",
       "      <td>3.872570</td>\n",
       "      <td>0.985745</td>\n",
       "      <td>0.368898</td>\n",
       "      <td>9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lares</td>\n",
       "      <td>gyx</td>\n",
       "      <td>11405.939622</td>\n",
       "      <td>3.885961</td>\n",
       "      <td>0.988337</td>\n",
       "      <td>0.357667</td>\n",
       "      <td>8</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rates</td>\n",
       "      <td>gyx</td>\n",
       "      <td>11580.717315</td>\n",
       "      <td>3.891577</td>\n",
       "      <td>0.987473</td>\n",
       "      <td>0.349460</td>\n",
       "      <td>9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arose</td>\n",
       "      <td>gyx</td>\n",
       "      <td>10958.212307</td>\n",
       "      <td>3.890713</td>\n",
       "      <td>0.982289</td>\n",
       "      <td>0.364147</td>\n",
       "      <td>9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rales</td>\n",
       "      <td>gyx</td>\n",
       "      <td>11737.313596</td>\n",
       "      <td>3.929158</td>\n",
       "      <td>0.985745</td>\n",
       "      <td>0.343413</td>\n",
       "      <td>9</td>\n",
       "      <td>45.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reais</td>\n",
       "      <td>gyx</td>\n",
       "      <td>11744.349903</td>\n",
       "      <td>3.921382</td>\n",
       "      <td>0.983153</td>\n",
       "      <td>0.346868</td>\n",
       "      <td>9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raise</td>\n",
       "      <td>gyx</td>\n",
       "      <td>10835.958220</td>\n",
       "      <td>3.913175</td>\n",
       "      <td>0.982289</td>\n",
       "      <td>0.355076</td>\n",
       "      <td>9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raile</td>\n",
       "      <td>gyx</td>\n",
       "      <td>9504.383956</td>\n",
       "      <td>3.922678</td>\n",
       "      <td>0.980562</td>\n",
       "      <td>0.361555</td>\n",
       "      <td>9</td>\n",
       "      <td>44.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lores</td>\n",
       "      <td>gyx</td>\n",
       "      <td>12474.869401</td>\n",
       "      <td>3.929158</td>\n",
       "      <td>0.984449</td>\n",
       "      <td>0.340821</td>\n",
       "      <td>8</td>\n",
       "      <td>45.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nares</td>\n",
       "      <td>gyx</td>\n",
       "      <td>11976.046848</td>\n",
       "      <td>3.937365</td>\n",
       "      <td>0.984881</td>\n",
       "      <td>0.337797</td>\n",
       "      <td>9</td>\n",
       "      <td>47.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dares</td>\n",
       "      <td>gyx</td>\n",
       "      <td>13469.079279</td>\n",
       "      <td>3.965875</td>\n",
       "      <td>0.982721</td>\n",
       "      <td>0.328726</td>\n",
       "      <td>9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Seed Word Ranking Algorithm       Runtime  Mean Steps  Success Rate  \\\n",
       "0     tores                lf    232.967899    3.730022      0.991793   \n",
       "0     tores            lf-pop    326.544851    3.739957      0.993089   \n",
       "0     tares                lf    225.392809    3.739093      0.991793   \n",
       "0     tares            lf-pop    328.405781    3.750324      0.992657   \n",
       "0     tales                lf    233.820936    3.749028      0.994384   \n",
       "0     arose                lf    223.036801    3.739525      0.990065   \n",
       "0     arose            lf-pop    376.123500    3.748596      0.989201   \n",
       "0     raise                lf    232.002648    3.742549      0.988769   \n",
       "0     tales            lf-pop    278.706187    3.769762      0.993089   \n",
       "0     roate            lf-pop    290.981662    3.765875      0.990929   \n",
       "0     roate                lf    196.688738    3.757235      0.990497   \n",
       "0     rales                lf    203.969526    3.784881      0.993952   \n",
       "0     raise            lf-pop    279.409335    3.754644      0.988337   \n",
       "0     rates            lf-pop    317.264952    3.790929      0.990929   \n",
       "0     rates                lf    239.049976    3.776242      0.990497   \n",
       "0     rales            lf-pop    315.789842    3.803888      0.993521   \n",
       "0     raile            lf-pop    336.500517    3.769330      0.989201   \n",
       "0     raile                lf    189.546732    3.758531      0.988337   \n",
       "0     arles                lf    234.079909    3.798704      0.990929   \n",
       "0     arles            lf-pop    346.197915    3.809935      0.991361   \n",
       "0     nares                lf    238.601038    3.808207      0.991793   \n",
       "0     soare                lf    225.832832    3.783153      0.987473   \n",
       "0     soare            lf-pop    278.151163    3.794384      0.987473   \n",
       "0     reais                lf    204.245565    3.803024      0.988769   \n",
       "0     nares            lf-pop    293.761462    3.822030      0.990929   \n",
       "0     lares                lf    245.787240    3.809503      0.990065   \n",
       "0     dares                lf    244.655717    3.816415      0.990929   \n",
       "0     dares            lf-pop    317.465164    3.828510      0.991361   \n",
       "0     tales               gyx  11917.266150    3.836285      0.990929   \n",
       "0     lares            lf-pop    342.221368    3.826782      0.990497   \n",
       "0     reais            lf-pop    329.681257    3.825918      0.987041   \n",
       "0     lores                lf    242.716667    3.846220      0.990929   \n",
       "0     lores            lf-pop    332.211099    3.854860      0.990497   \n",
       "0     roate               gyx  10169.933737    3.837149      0.985745   \n",
       "0     tares               gyx   8236.806425    3.846652      0.988337   \n",
       "0     arles               gyx  11323.127547    3.880346      0.989201   \n",
       "0     soare               gyx  10150.235974    3.857883      0.982721   \n",
       "0     tores               gyx  11760.894683    3.872570      0.985745   \n",
       "0     lares               gyx  11405.939622    3.885961      0.988337   \n",
       "0     rates               gyx  11580.717315    3.891577      0.987473   \n",
       "0     arose               gyx  10958.212307    3.890713      0.982289   \n",
       "0     rales               gyx  11737.313596    3.929158      0.985745   \n",
       "0     reais               gyx  11744.349903    3.921382      0.983153   \n",
       "0     raise               gyx  10835.958220    3.913175      0.982289   \n",
       "0     raile               gyx   9504.383956    3.922678      0.980562   \n",
       "0     lores               gyx  12474.869401    3.929158      0.984449   \n",
       "0     nares               gyx  11976.046848    3.937365      0.984881   \n",
       "0     dares               gyx  13469.079279    3.965875      0.982721   \n",
       "\n",
       "   3-Steps or Less  Worst Case  steps_rank  success_rank  threestep_rank  \\\n",
       "0         0.425054           8         1.0           8.0             3.5   \n",
       "0         0.423758           8         4.0           4.5             5.0   \n",
       "0         0.419438           8         2.0           8.0             7.5   \n",
       "0         0.419438           8         8.0           6.0             7.5   \n",
       "0         0.395680           8         7.0           1.0            17.0   \n",
       "0         0.429806           8         3.0          23.5             2.0   \n",
       "0         0.430238           8         6.0          26.0             1.0   \n",
       "0         0.425054           9         5.0          28.5             3.5   \n",
       "0         0.393521           8        14.0           4.5            20.0   \n",
       "0         0.415551           9        12.0          15.0            12.0   \n",
       "0         0.417279           9        10.0          20.5            10.0   \n",
       "0         0.387905           8        17.0           2.0            22.0   \n",
       "0         0.422462           9         9.0          31.5             6.0   \n",
       "0         0.403024           9        18.0          15.0            16.0   \n",
       "0         0.404320           9        15.0          20.5            14.0   \n",
       "0         0.385313           8        22.0           3.0            25.0   \n",
       "0         0.416415           9        13.0          26.0            11.0   \n",
       "0         0.418575           9        11.0          31.5             9.0   \n",
       "0         0.388337          10        20.0          15.0            21.0   \n",
       "0         0.386609           9        25.0          10.5            23.0   \n",
       "0         0.381857           8        23.0           8.0            28.0   \n",
       "0         0.403888           8        16.0          35.0            15.0   \n",
       "0         0.404752           8        19.0          35.0            13.0   \n",
       "0         0.394816           9        21.0          28.5            18.0   \n",
       "0         0.382289           8        27.0          15.0            27.0   \n",
       "0         0.384017           8        24.0          23.5            26.0   \n",
       "0         0.369762           8        26.0          15.0            33.0   \n",
       "0         0.368467           8        30.0          10.5            35.0   \n",
       "0         0.371058           9        31.0          15.0            32.0   \n",
       "0         0.380562           8        29.0          20.5            30.0   \n",
       "0         0.393952           9        28.0          37.0            19.0   \n",
       "0         0.367603           9        33.0          15.0            36.5   \n",
       "0         0.367603           9        35.0          20.5            36.5   \n",
       "0         0.385745           9        32.0          39.0            24.0   \n",
       "0         0.371490           9        34.0          31.5            31.0   \n",
       "0         0.358099           8        38.0          26.0            40.0   \n",
       "0         0.381425           9        36.0          44.5            29.0   \n",
       "0         0.368898           9        37.0          39.0            34.0   \n",
       "0         0.357667           8        39.0          31.5            41.0   \n",
       "0         0.349460           9        41.0          35.0            43.0   \n",
       "0         0.364147           9        40.0          46.5            38.0   \n",
       "0         0.343413           9        45.5          39.0            45.0   \n",
       "0         0.346868           9        43.0          43.0            44.0   \n",
       "0         0.355076           9        42.0          46.5            42.0   \n",
       "0         0.361555           9        44.0          48.0            39.0   \n",
       "0         0.340821           8        45.5          42.0            46.0   \n",
       "0         0.337797           9        47.0          41.0            47.0   \n",
       "0         0.328726           9        48.0          44.5            48.0   \n",
       "\n",
       "    avg_rank  \n",
       "0   4.166667  \n",
       "0   4.500000  \n",
       "0   5.833333  \n",
       "0   7.166667  \n",
       "0   8.333333  \n",
       "0   9.500000  \n",
       "0  11.000000  \n",
       "0  12.333333  \n",
       "0  12.833333  \n",
       "0  13.000000  \n",
       "0  13.500000  \n",
       "0  13.666667  \n",
       "0  15.500000  \n",
       "0  16.333333  \n",
       "0  16.500000  \n",
       "0  16.666667  \n",
       "0  16.666667  \n",
       "0  17.166667  \n",
       "0  18.666667  \n",
       "0  19.500000  \n",
       "0  19.666667  \n",
       "0  22.000000  \n",
       "0  22.333333  \n",
       "0  22.500000  \n",
       "0  23.000000  \n",
       "0  24.500000  \n",
       "0  24.666667  \n",
       "0  25.166667  \n",
       "0  26.000000  \n",
       "0  26.500000  \n",
       "0  28.000000  \n",
       "0  28.166667  \n",
       "0  30.666667  \n",
       "0  31.666667  \n",
       "0  32.166667  \n",
       "0  34.666667  \n",
       "0  36.500000  \n",
       "0  36.666667  \n",
       "0  37.166667  \n",
       "0  39.666667  \n",
       "0  41.500000  \n",
       "0  43.166667  \n",
       "0  43.333333  \n",
       "0  43.500000  \n",
       "0  43.666667  \n",
       "0  44.500000  \n",
       "0  45.000000  \n",
       "0  46.833333  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('avg_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb75edff-3d0f-47c8-8159-442d27c2d960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('Ranking Algorithm')['Mean Steps'].plot.hist(alpha=0.4, bins=5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f0f52c-289d-493c-b549-d2a67c000c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed Word</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Mean Steps</th>\n",
       "      <th>Success Rate</th>\n",
       "      <th>3-Steps or Less</th>\n",
       "      <th>Worst Case</th>\n",
       "      <th>steps_rank</th>\n",
       "      <th>success_rank</th>\n",
       "      <th>threestep_rank</th>\n",
       "      <th>avg_rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gyx</th>\n",
       "      <td>stare</td>\n",
       "      <td>10812.406851</td>\n",
       "      <td>3.831965</td>\n",
       "      <td>0.989201</td>\n",
       "      <td>0.377538</td>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf</th>\n",
       "      <td>stare</td>\n",
       "      <td>236.935718</td>\n",
       "      <td>3.728726</td>\n",
       "      <td>0.991793</td>\n",
       "      <td>0.423758</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Seed Word       Runtime  Mean Steps  Success Rate  \\\n",
       "Ranking Algorithm                                                     \n",
       "gyx                   stare  10812.406851    3.831965      0.989201   \n",
       "lf                    stare    236.935718    3.728726      0.991793   \n",
       "\n",
       "                   3-Steps or Less  Worst Case  steps_rank  success_rank  \\\n",
       "Ranking Algorithm                                                          \n",
       "gyx                       0.377538           9        17.0          15.5   \n",
       "lf                        0.423758           9         1.0           4.5   \n",
       "\n",
       "                   threestep_rank   avg_rank  \n",
       "Ranking Algorithm                             \n",
       "gyx                          18.0  16.833333  \n",
       "lf                            4.0   3.166667  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('Mean Steps').groupby('Ranking Algorithm').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "267f2e69-fd42-451e-9675-4c8b93094d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X = df[['Seed Word', 'Ranking Algorithm']].copy()\n",
    "X.loc[X['Seed Word'].eq('stare'), 'Seed Word'] = '0stare'\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X['const'] = 1.0\n",
    "y1 = df['Mean Steps']\n",
    "y2 = df['Success Rate']\n",
    "y3 = df['3-Steps or Less']\n",
    "\n",
    "lm1 = sm.OLS(y1, X)\n",
    "lm2 = sm.OLS(y2, X)\n",
    "lm3 = sm.OLS(y3, X)\n",
    "\n",
    "res1 = lm1.fit()\n",
    "res2 = lm2.fit()\n",
    "res3 = lm3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fe75e57-8e0c-43da-8d76-9589377c0654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Mean Steps</td>    <th>  R-squared:         </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 01 Feb 2022</td> <th>  Prob (F-statistic):</th> <td>4.35e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:59:29</td>     <th>  Log-Likelihood:    </th> <td>  92.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    34</td>      <th>  AIC:               </th> <td>  -149.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    16</td>      <th>  BIC:               </th> <td>  -121.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_arles</th>      <td>    0.0592</td> <td>    0.023</td> <td>    2.549</td> <td> 0.021</td> <td>    0.010</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_arose</th>      <td>    0.0348</td> <td>    0.023</td> <td>    1.498</td> <td> 0.154</td> <td>   -0.014</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_dares</th>      <td>    0.1108</td> <td>    0.023</td> <td>    4.773</td> <td> 0.000</td> <td>    0.062</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_lares</th>      <td>    0.0674</td> <td>    0.023</td> <td>    2.903</td> <td> 0.010</td> <td>    0.018</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_lores</th>      <td>    0.1073</td> <td>    0.023</td> <td>    4.624</td> <td> 0.000</td> <td>    0.058</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_nares</th>      <td>    0.0924</td> <td>    0.023</td> <td>    3.982</td> <td> 0.001</td> <td>    0.043</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_raile</th>      <td>    0.0603</td> <td>    0.023</td> <td>    2.596</td> <td> 0.020</td> <td>    0.011</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_raise</th>      <td>    0.0475</td> <td>    0.023</td> <td>    2.047</td> <td> 0.057</td> <td>   -0.002</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_rales</th>      <td>    0.0767</td> <td>    0.023</td> <td>    3.303</td> <td> 0.004</td> <td>    0.027</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_rates</th>      <td>    0.0536</td> <td>    0.023</td> <td>    2.307</td> <td> 0.035</td> <td>    0.004</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_reais</th>      <td>    0.0819</td> <td>    0.023</td> <td>    3.526</td> <td> 0.003</td> <td>    0.033</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_roate</th>      <td>    0.0168</td> <td>    0.023</td> <td>    0.726</td> <td> 0.478</td> <td>   -0.032</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_soare</th>      <td>    0.0402</td> <td>    0.023</td> <td>    1.731</td> <td> 0.103</td> <td>   -0.009</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_tales</th>      <td>    0.0123</td> <td>    0.023</td> <td>    0.530</td> <td> 0.603</td> <td>   -0.037</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_tares</th>      <td>    0.0125</td> <td>    0.023</td> <td>    0.540</td> <td> 0.597</td> <td>   -0.037</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_tores</th>      <td>    0.0210</td> <td>    0.023</td> <td>    0.903</td> <td> 0.380</td> <td>   -0.028</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ranking Algorithm_lf</th> <td>   -0.1164</td> <td>    0.008</td> <td>  -14.619</td> <td> 0.000</td> <td>   -0.133</td> <td>   -0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    3.8385</td> <td>    0.017</td> <td>  227.264</td> <td> 0.000</td> <td>    3.803</td> <td>    3.874</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.548</td> <th>  Durbin-Watson:     </th> <td>   2.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>   2.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.000</td> <th>  Prob(JB):          </th> <td>   0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.624</td> <th>  Cond. No.          </th> <td>    20.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Mean Steps   R-squared:                       0.946\n",
       "Model:                            OLS   Adj. R-squared:                  0.889\n",
       "Method:                 Least Squares   F-statistic:                     16.61\n",
       "Date:                Tue, 01 Feb 2022   Prob (F-statistic):           4.35e-07\n",
       "Time:                        20:59:29   Log-Likelihood:                 92.513\n",
       "No. Observations:                  34   AIC:                            -149.0\n",
       "Df Residuals:                      16   BIC:                            -121.6\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Seed Word_arles          0.0592      0.023      2.549      0.021       0.010       0.108\n",
       "Seed Word_arose          0.0348      0.023      1.498      0.154      -0.014       0.084\n",
       "Seed Word_dares          0.1108      0.023      4.773      0.000       0.062       0.160\n",
       "Seed Word_lares          0.0674      0.023      2.903      0.010       0.018       0.117\n",
       "Seed Word_lores          0.1073      0.023      4.624      0.000       0.058       0.157\n",
       "Seed Word_nares          0.0924      0.023      3.982      0.001       0.043       0.142\n",
       "Seed Word_raile          0.0603      0.023      2.596      0.020       0.011       0.109\n",
       "Seed Word_raise          0.0475      0.023      2.047      0.057      -0.002       0.097\n",
       "Seed Word_rales          0.0767      0.023      3.303      0.004       0.027       0.126\n",
       "Seed Word_rates          0.0536      0.023      2.307      0.035       0.004       0.103\n",
       "Seed Word_reais          0.0819      0.023      3.526      0.003       0.033       0.131\n",
       "Seed Word_roate          0.0168      0.023      0.726      0.478      -0.032       0.066\n",
       "Seed Word_soare          0.0402      0.023      1.731      0.103      -0.009       0.089\n",
       "Seed Word_tales          0.0123      0.023      0.530      0.603      -0.037       0.062\n",
       "Seed Word_tares          0.0125      0.023      0.540      0.597      -0.037       0.062\n",
       "Seed Word_tores          0.0210      0.023      0.903      0.380      -0.028       0.070\n",
       "Ranking Algorithm_lf    -0.1164      0.008    -14.619      0.000      -0.133      -0.100\n",
       "const                    3.8385      0.017    227.264      0.000       3.803       3.874\n",
       "==============================================================================\n",
       "Omnibus:                       12.548   Durbin-Watson:                   2.157\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):                2.683\n",
       "Skew:                          -0.000   Prob(JB):                        0.262\n",
       "Kurtosis:                       1.624   Cond. No.                         20.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78083f1-3ad0-4fa8-a686-55a33908896b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71c8ac41-ccce-4ea3-aed1-07edba448cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Success Rate</td>   <th>  R-squared:         </th> <td>   0.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 01 Feb 2022</td> <th>  Prob (F-statistic):</th> <td>2.81e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:00:00</td>     <th>  Log-Likelihood:    </th> <td>  183.74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    34</td>      <th>  AIC:               </th> <td>  -331.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    16</td>      <th>  BIC:               </th> <td>  -304.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_arles</th>      <td>   -0.0004</td> <td>    0.002</td> <td>   -0.272</td> <td> 0.789</td> <td>   -0.004</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_arose</th>      <td>   -0.0043</td> <td>    0.002</td> <td>   -2.722</td> <td> 0.015</td> <td>   -0.008</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_dares</th>      <td>   -0.0037</td> <td>    0.002</td> <td>   -2.314</td> <td> 0.034</td> <td>   -0.007</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_lares</th>      <td>   -0.0013</td> <td>    0.002</td> <td>   -0.817</td> <td> 0.426</td> <td>   -0.005</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_lores</th>      <td>   -0.0028</td> <td>    0.002</td> <td>   -1.770</td> <td> 0.096</td> <td>   -0.006</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_nares</th>      <td>   -0.0022</td> <td>    0.002</td> <td>   -1.361</td> <td> 0.192</td> <td>   -0.006</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_raile</th>      <td>   -0.0060</td> <td>    0.002</td> <td>   -3.811</td> <td> 0.002</td> <td>   -0.009</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_raise</th>      <td>   -0.0050</td> <td>    0.002</td> <td>   -3.131</td> <td> 0.006</td> <td>   -0.008</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_rales</th>      <td>   -0.0006</td> <td>    0.002</td> <td>   -0.408</td> <td> 0.688</td> <td>   -0.004</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_rates</th>      <td>   -0.0015</td> <td>    0.002</td> <td>   -0.953</td> <td> 0.355</td> <td>   -0.005</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_reais</th>      <td>   -0.0045</td> <td>    0.002</td> <td>   -2.859</td> <td> 0.011</td> <td>   -0.008</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_roate</th>      <td>   -0.0024</td> <td>    0.002</td> <td>   -1.497</td> <td> 0.154</td> <td>   -0.006</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_soare</th>      <td>   -0.0054</td> <td>    0.002</td> <td>   -3.403</td> <td> 0.004</td> <td>   -0.009</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_tales</th>      <td>    0.0022</td> <td>    0.002</td> <td>    1.361</td> <td> 0.192</td> <td>   -0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_tares</th>      <td>   -0.0004</td> <td>    0.002</td> <td>   -0.272</td> <td> 0.789</td> <td>   -0.004</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_tores</th>      <td>   -0.0017</td> <td>    0.002</td> <td>   -1.089</td> <td> 0.292</td> <td>   -0.005</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ranking Algorithm_lf</th> <td>    0.0052</td> <td>    0.001</td> <td>    9.618</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.9879</td> <td>    0.001</td> <td>  855.677</td> <td> 0.000</td> <td>    0.985</td> <td>    0.990</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.555</td> <th>  Durbin-Watson:     </th> <td>   2.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.008</td> <th>  Jarque-Bera (JB):  </th> <td>   2.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.000</td> <th>  Prob(JB):          </th> <td>   0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.697</td> <th>  Cond. No.          </th> <td>    20.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           Success Rate   R-squared:                       0.906\n",
       "Model:                            OLS   Adj. R-squared:                  0.807\n",
       "Method:                 Least Squares   F-statistic:                     9.123\n",
       "Date:                Tue, 01 Feb 2022   Prob (F-statistic):           2.81e-05\n",
       "Time:                        21:00:00   Log-Likelihood:                 183.74\n",
       "No. Observations:                  34   AIC:                            -331.5\n",
       "Df Residuals:                      16   BIC:                            -304.0\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Seed Word_arles         -0.0004      0.002     -0.272      0.789      -0.004       0.003\n",
       "Seed Word_arose         -0.0043      0.002     -2.722      0.015      -0.008      -0.001\n",
       "Seed Word_dares         -0.0037      0.002     -2.314      0.034      -0.007      -0.000\n",
       "Seed Word_lares         -0.0013      0.002     -0.817      0.426      -0.005       0.002\n",
       "Seed Word_lores         -0.0028      0.002     -1.770      0.096      -0.006       0.001\n",
       "Seed Word_nares         -0.0022      0.002     -1.361      0.192      -0.006       0.001\n",
       "Seed Word_raile         -0.0060      0.002     -3.811      0.002      -0.009      -0.003\n",
       "Seed Word_raise         -0.0050      0.002     -3.131      0.006      -0.008      -0.002\n",
       "Seed Word_rales         -0.0006      0.002     -0.408      0.688      -0.004       0.003\n",
       "Seed Word_rates         -0.0015      0.002     -0.953      0.355      -0.005       0.002\n",
       "Seed Word_reais         -0.0045      0.002     -2.859      0.011      -0.008      -0.001\n",
       "Seed Word_roate         -0.0024      0.002     -1.497      0.154      -0.006       0.001\n",
       "Seed Word_soare         -0.0054      0.002     -3.403      0.004      -0.009      -0.002\n",
       "Seed Word_tales          0.0022      0.002      1.361      0.192      -0.001       0.006\n",
       "Seed Word_tares         -0.0004      0.002     -0.272      0.789      -0.004       0.003\n",
       "Seed Word_tores         -0.0017      0.002     -1.089      0.292      -0.005       0.002\n",
       "Ranking Algorithm_lf     0.0052      0.001      9.618      0.000       0.004       0.006\n",
       "const                    0.9879      0.001    855.677      0.000       0.985       0.990\n",
       "==============================================================================\n",
       "Omnibus:                        9.555   Durbin-Watson:                   2.557\n",
       "Prob(Omnibus):                  0.008   Jarque-Bera (JB):                2.405\n",
       "Skew:                           0.000   Prob(JB):                        0.300\n",
       "Kurtosis:                       1.697   Cond. No.                         20.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2295915-bb07-4bfb-8aca-f725885c55a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>3-Steps or Less</td> <th>  R-squared:         </th> <td>   0.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 01 Feb 2022</td> <th>  Prob (F-statistic):</th> <td>1.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:00:01</td>     <th>  Log-Likelihood:    </th> <td>  120.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    34</td>      <th>  AIC:               </th> <td>  -204.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    16</td>      <th>  BIC:               </th> <td>  -176.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_arles</th>      <td>   -0.0274</td> <td>    0.010</td> <td>   -2.657</td> <td> 0.017</td> <td>   -0.049</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_arose</th>      <td>   -0.0037</td> <td>    0.010</td> <td>   -0.356</td> <td> 0.727</td> <td>   -0.026</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_dares</th>      <td>   -0.0514</td> <td>    0.010</td> <td>   -4.980</td> <td> 0.000</td> <td>   -0.073</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_lares</th>      <td>   -0.0298</td> <td>    0.010</td> <td>   -2.887</td> <td> 0.011</td> <td>   -0.052</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_lores</th>      <td>   -0.0464</td> <td>    0.010</td> <td>   -4.498</td> <td> 0.000</td> <td>   -0.068</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_nares</th>      <td>   -0.0408</td> <td>    0.010</td> <td>   -3.954</td> <td> 0.001</td> <td>   -0.063</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_raile</th>      <td>   -0.0106</td> <td>    0.010</td> <td>   -1.025</td> <td> 0.321</td> <td>   -0.032</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_raise</th>      <td>   -0.0106</td> <td>    0.010</td> <td>   -1.025</td> <td> 0.321</td> <td>   -0.032</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_rales</th>      <td>   -0.0350</td> <td>    0.010</td> <td>   -3.390</td> <td> 0.004</td> <td>   -0.057</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_rates</th>      <td>   -0.0238</td> <td>    0.010</td> <td>   -2.302</td> <td> 0.035</td> <td>   -0.046</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_reais</th>      <td>   -0.0298</td> <td>    0.010</td> <td>   -2.887</td> <td> 0.011</td> <td>   -0.052</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_roate</th>      <td>    0.0009</td> <td>    0.010</td> <td>    0.084</td> <td> 0.934</td> <td>   -0.021</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_soare</th>      <td>   -0.0080</td> <td>    0.010</td> <td>   -0.774</td> <td> 0.450</td> <td>   -0.030</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_tales</th>      <td>   -0.0173</td> <td>    0.010</td> <td>   -1.674</td> <td> 0.114</td> <td>   -0.039</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_tares</th>      <td>   -0.0052</td> <td>    0.010</td> <td>   -0.502</td> <td> 0.622</td> <td>   -0.027</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Seed Word_tores</th>      <td>   -0.0037</td> <td>    0.010</td> <td>   -0.356</td> <td> 0.727</td> <td>   -0.026</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ranking Algorithm_lf</th> <td>    0.0434</td> <td>    0.004</td> <td>   12.250</td> <td> 0.000</td> <td>    0.036</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.3790</td> <td>    0.008</td> <td>   50.455</td> <td> 0.000</td> <td>    0.363</td> <td>    0.395</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.289</td> <th>  Durbin-Watson:     </th> <td>   2.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.193</td> <th>  Jarque-Bera (JB):  </th> <td>   1.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.000</td> <th>  Prob(JB):          </th> <td>   0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.976</td> <th>  Cond. No.          </th> <td>    20.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        3-Steps or Less   R-squared:                       0.936\n",
       "Model:                            OLS   Adj. R-squared:                  0.868\n",
       "Method:                 Least Squares   F-statistic:                     13.82\n",
       "Date:                Tue, 01 Feb 2022   Prob (F-statistic):           1.62e-06\n",
       "Time:                        21:00:01   Log-Likelihood:                 120.07\n",
       "No. Observations:                  34   AIC:                            -204.1\n",
       "Df Residuals:                      16   BIC:                            -176.7\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Seed Word_arles         -0.0274      0.010     -2.657      0.017      -0.049      -0.006\n",
       "Seed Word_arose         -0.0037      0.010     -0.356      0.727      -0.026       0.018\n",
       "Seed Word_dares         -0.0514      0.010     -4.980      0.000      -0.073      -0.030\n",
       "Seed Word_lares         -0.0298      0.010     -2.887      0.011      -0.052      -0.008\n",
       "Seed Word_lores         -0.0464      0.010     -4.498      0.000      -0.068      -0.025\n",
       "Seed Word_nares         -0.0408      0.010     -3.954      0.001      -0.063      -0.019\n",
       "Seed Word_raile         -0.0106      0.010     -1.025      0.321      -0.032       0.011\n",
       "Seed Word_raise         -0.0106      0.010     -1.025      0.321      -0.032       0.011\n",
       "Seed Word_rales         -0.0350      0.010     -3.390      0.004      -0.057      -0.013\n",
       "Seed Word_rates         -0.0238      0.010     -2.302      0.035      -0.046      -0.002\n",
       "Seed Word_reais         -0.0298      0.010     -2.887      0.011      -0.052      -0.008\n",
       "Seed Word_roate          0.0009      0.010      0.084      0.934      -0.021       0.023\n",
       "Seed Word_soare         -0.0080      0.010     -0.774      0.450      -0.030       0.014\n",
       "Seed Word_tales         -0.0173      0.010     -1.674      0.114      -0.039       0.005\n",
       "Seed Word_tares         -0.0052      0.010     -0.502      0.622      -0.027       0.017\n",
       "Seed Word_tores         -0.0037      0.010     -0.356      0.727      -0.026       0.018\n",
       "Ranking Algorithm_lf     0.0434      0.004     12.250      0.000       0.036       0.051\n",
       "const                    0.3790      0.008     50.455      0.000       0.363       0.395\n",
       "==============================================================================\n",
       "Omnibus:                        3.289   Durbin-Watson:                   2.008\n",
       "Prob(Omnibus):                  0.193   Jarque-Bera (JB):                1.486\n",
       "Skew:                          -0.000   Prob(JB):                        0.476\n",
       "Kurtosis:                       1.976   Cond. No.                         20.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ebea74-2530-407a-85dc-7f1d922ff6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seed Word\n",
       "arles    2\n",
       "arose    2\n",
       "dares    2\n",
       "lares    2\n",
       "lores    2\n",
       "nares    2\n",
       "raile    2\n",
       "raise    2\n",
       "rales    2\n",
       "rates    2\n",
       "reais    2\n",
       "roate    2\n",
       "soare    2\n",
       "stare    2\n",
       "tales    2\n",
       "tares    2\n",
       "tores    2\n",
       "Name: Ranking Algorithm, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Seed Word')['Ranking Algorithm'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bfbb68-9643-47d3-a060-fdbfc4223215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b33a111-f8fa-401e-a799-30a9723e3a23",
   "metadata": {},
   "source": [
    "## All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22ba646-664b-475d-bee9-18975fb83580",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Unnamed: 0' in all_data.columns:\n",
    "    all_data = all_data.drop('Unnamed: 0', axis=1)\n",
    "all_data['words'] = all_data.words.apply(eval)\n",
    "all_data['word'] = all_data.words.apply(lambda x: x[0])\n",
    "all_data['solution'] = all_data.words.apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17cb562b-6c44-4515-9a81-2f65a23449ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsolved = all_data.groupby(['solution', 'method']).steps.mean().reset_index()\n",
    "unsolved = unsolved.loc[unsolved.steps.gt(6)].sort_values('steps', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b625dea-ef44-48a5-b285-c2921ae07df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution</th>\n",
       "      <th>method</th>\n",
       "      <th>steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>baker</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>baste</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>baste</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>batch</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>bluer</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>boxer</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>boxer</td>\n",
       "      <td>lf</td>\n",
       "      <td>7.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>brown</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>brown</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>buyer</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>caper</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>catch</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>cower</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>crone</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>cyber</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>daddy</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>daunt</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>eater</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>fight</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>flake</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>foyer</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>gazer</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>goner</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>grape</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>graze</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>graze</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>happy</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>haste</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>hatch</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>homer</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>hound</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>hound</td>\n",
       "      <td>lf</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>hunch</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>hyper</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>jazzy</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>joker</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>joker</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>jolly</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>judge</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>maker</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>match</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>match</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>miner</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>mover</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>mower</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>patch</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>shape</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>shave</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>snore</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033</th>\n",
       "      <td>taste</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>tatty</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>taunt</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>vaunt</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>vaunt</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>wafer</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>water</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4468</th>\n",
       "      <td>waver</td>\n",
       "      <td>gyx</td>\n",
       "      <td>7.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>willy</td>\n",
       "      <td>gyx</td>\n",
       "      <td>6.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4539</th>\n",
       "      <td>willy</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>witty</td>\n",
       "      <td>lf</td>\n",
       "      <td>6.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>wound</td>\n",
       "      <td>lf</td>\n",
       "      <td>7.176471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     solution method     steps\n",
       "292     baker    gyx  6.117647\n",
       "317     baste     lf  6.941176\n",
       "316     baste    gyx  7.235294\n",
       "318     batch    gyx  7.294118\n",
       "460     bluer    gyx  6.117647\n",
       "514     boxer    gyx  7.823529\n",
       "515     boxer     lf  7.764706\n",
       "579     brown     lf  6.411765\n",
       "578     brown    gyx  6.294118\n",
       "624     buyer    gyx  6.529412\n",
       "664     caper    gyx  6.058824\n",
       "681     catch     lf  6.176471\n",
       "906     cower    gyx  6.176471\n",
       "972     crone    gyx  6.117647\n",
       "1018    cyber    gyx  6.411765\n",
       "1025    daddy     lf  6.294118\n",
       "1040    daunt    gyx  6.352941\n",
       "1259    eater     lf  6.176471\n",
       "1466    fight    gyx  6.882353\n",
       "1500    flake    gyx  6.117647\n",
       "1599    foyer     lf  6.058824\n",
       "1690    gazer    gyx  6.117647\n",
       "1766    goner    gyx  6.117647\n",
       "1796    grape    gyx  6.058824\n",
       "1810    graze    gyx  7.117647\n",
       "1811    graze     lf  6.411765\n",
       "1900    happy    gyx  7.588235\n",
       "1912    haste    gyx  6.235294\n",
       "1917    hatch     lf  6.941176\n",
       "1974    homer    gyx  6.352941\n",
       "1990    hound    gyx  6.352941\n",
       "1991    hound     lf  7.000000\n",
       "2011    hunch     lf  6.176471\n",
       "2028    hyper    gyx  6.529412\n",
       "2100    jazzy    gyx  6.411765\n",
       "2117    joker     lf  6.235294\n",
       "2116    joker    gyx  6.294118\n",
       "2119    jolly     lf  6.058824\n",
       "2122    judge    gyx  6.411765\n",
       "2374    maker    gyx  7.117647\n",
       "2411    match     lf  6.470588\n",
       "2410    match    gyx  7.294118\n",
       "2468    miner    gyx  6.176471\n",
       "2536    mover    gyx  6.352941\n",
       "2540    mower    gyx  7.411765\n",
       "2760    patch    gyx  6.294118\n",
       "3418    shape    gyx  6.235294\n",
       "3429    shave     lf  6.882353\n",
       "3654    snore    gyx  6.294118\n",
       "4033    taste     lf  6.941176\n",
       "4037    tatty     lf  6.176471\n",
       "4039    taunt     lf  6.058824\n",
       "4379    vaunt     lf  6.764706\n",
       "4378    vaunt    gyx  7.411765\n",
       "4448    wafer    gyx  7.588235\n",
       "4466    water    gyx  6.764706\n",
       "4468    waver    gyx  7.352941\n",
       "4538    willy    gyx  6.294118\n",
       "4539    willy     lf  6.882353\n",
       "4555    witty     lf  6.117647\n",
       "4585    wound     lf  7.176471"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows=100\n",
    "unsolved.sort_values('solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4e7f9-6616-451c-a593-4f78ab85d0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea78dd4-45ce-4979-a517-d7772ff9912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wordlebot\n",
    "\n",
    "from wordlebot import Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ac5741-4cad-4b60-8b6e-c5e5f0695983",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordle_candidates, wordle_answers = wordlebot.load_data('data')\n",
    "wordle = wordle_candidates.loc[\n",
    "    wordle_candidates.word.apply(lambda x: len(x)==len(set(x)))\n",
    "].append(wordle_answers).reset_index(drop=True)\n",
    "\n",
    "word_popularity = wordlebot.load_word_popularity('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd61aad-d1cc-47f8-9fa9-85b19955ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = wordlebot.Wordle(wordle, wordle_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d524957-cd24-4b08-b05c-522e3f908200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARE --> YYXXG: 3 solutions remaining.\n"
     ]
    }
   ],
   "source": [
    "game.guess('stare', 'yyxxg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0ce651-8c04-4f6c-92cf-0f51d68c4dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4392b8c875d7478183ab24b827ff3ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   9 out of   9 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ncands_max</th>\n",
       "      <th>ncands_mean</th>\n",
       "      <th>nbuckets</th>\n",
       "      <th>bucket_entropy</th>\n",
       "      <th>ncands_max_rank</th>\n",
       "      <th>ncands_mean_rank</th>\n",
       "      <th>bucket_entropy_rank</th>\n",
       "      <th>avg_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>these</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>those</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tense</td>\n",
       "      <td>2</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.636514</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  ncands_max  ncands_mean  nbuckets  bucket_entropy  ncands_max_rank  \\\n",
       "0  these           1     1.000000         3        1.098612              1.5   \n",
       "1  those           1     1.000000         3        1.098612              1.5   \n",
       "2  tense           2     1.666667         2        0.636514              3.0   \n",
       "\n",
       "   ncands_mean_rank  bucket_entropy_rank  avg_rank  \n",
       "0               1.5                  1.5       1.5  \n",
       "1               1.5                  1.5       1.5  \n",
       "2               3.0                  3.0       3.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.optimise('ncands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ac9d96e-52b1-41f7-a4e0-17b4ddd27cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>letter_a</th>\n",
       "      <th>letter_b</th>\n",
       "      <th>letter_c</th>\n",
       "      <th>letter_d</th>\n",
       "      <th>...</th>\n",
       "      <th>letter_s</th>\n",
       "      <th>letter_t</th>\n",
       "      <th>letter_u</th>\n",
       "      <th>letter_v</th>\n",
       "      <th>letter_w</th>\n",
       "      <th>letter_x</th>\n",
       "      <th>letter_y</th>\n",
       "      <th>letter_z</th>\n",
       "      <th>word_freq</th>\n",
       "      <th>n_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>these</td>\n",
       "      <td>t</td>\n",
       "      <td>h</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215479</td>\n",
       "      <td>175528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>those</td>\n",
       "      <td>t</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100339</td>\n",
       "      <td>87288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tense</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1302</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    word p0 p1 p2 p3 p4  letter_a  letter_b  letter_c  letter_d  ...  \\\n",
       "2  these  t  h  e  s  e         0         0         0         0  ...   \n",
       "0  those  t  h  o  s  e         0         0         0         0  ...   \n",
       "1  tense  t  e  n  s  e         0         0         0         0  ...   \n",
       "\n",
       "   letter_s  letter_t  letter_u  letter_v  letter_w  letter_x  letter_y  \\\n",
       "2         1         1         0         0         0         0         0   \n",
       "0         1         1         0         0         0         0         0   \n",
       "1         1         1         0         0         0         0         0   \n",
       "\n",
       "   letter_z  word_freq  n_articles  \n",
       "2         0     215479      175528  \n",
       "0         0     100339       87288  \n",
       "1         0       1302         934  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.reprioritise(data=word_popularity, plugin='popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd78434-40e4-401e-a7a5-01df09ca4f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THESE --> GGYGG: 1 solutions remaining.\n",
      "Game autosolved. Last guess: THOSE\n",
      "Game solved in 3 steps.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>feedback</th>\n",
       "      <th>n_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stare</td>\n",
       "      <td>YYXXG</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these</td>\n",
       "      <td>GGYGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>those</td>\n",
       "      <td>GGGGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word feedback  n_candidates\n",
       "0  stare    YYXXG             3\n",
       "1  these    GGYGG             1\n",
       "2  those    GGGGG             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game.guess('these', 'ggygg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd6ecc-a207-45e7-aa68-4fadb3eaf7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
