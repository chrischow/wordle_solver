{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc3de08-88be-469e-b666-9f43457246c4",
   "metadata": {},
   "source": [
    "# Brute Force with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9663d273-9e91-4410-a674-7996d3f970a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a9b42-87a4-4875-b94d-ae25c967c174",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3190d2c3-b54e-4c03-b528-0dc85a1f0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wordle-candidates.json', 'r') as file:\n",
    "    wordle_candidates = json.load(file)\n",
    "    \n",
    "with open('data/wordle-answers.json', 'r') as file:\n",
    "    wordle_answers = json.load(file)\n",
    "\n",
    "wordle_candidates = pd.DataFrame(wordle_candidates['words'], columns=['word'])\n",
    "wordle_answers = pd.DataFrame(wordle_answers['words'], columns=['word'])\n",
    "wordle_candidates['is_answer'] = 0\n",
    "wordle_answers['is_answer'] = 1\n",
    "wordle = wordle_candidates.loc[wordle_candidates.word.apply(lambda x: len(x)==len(set(x)))].append(wordle_answers).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4273010f-6e69-4305-9c65-35216873bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_all = pd.read_table('data/archive/en_words_1_5-5.txt', delimiter=' ', header=None, index_col=None,\n",
    "                         names=['word_len', 'word_freq', 'n_articles']).reset_index()\n",
    "words_all = words_all.rename(columns={'index': 'word'})\n",
    "\n",
    "# Filter by english\n",
    "alphabet = list('abcdefghijklmnopqrstuvwxyz')\n",
    "words_all = words_all.loc[words_all.word.apply(lambda x: all([l in alphabet for l in x]))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3b96511e-0ceb-4dcf-83f8-997f16694f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_len</th>\n",
       "      <th>word_freq</th>\n",
       "      <th>n_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which</td>\n",
       "      <td>5</td>\n",
       "      <td>1220752</td>\n",
       "      <td>890394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first</td>\n",
       "      <td>5</td>\n",
       "      <td>1033698</td>\n",
       "      <td>751444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>known</td>\n",
       "      <td>5</td>\n",
       "      <td>742591</td>\n",
       "      <td>654233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>after</td>\n",
       "      <td>5</td>\n",
       "      <td>694687</td>\n",
       "      <td>537462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>their</td>\n",
       "      <td>5</td>\n",
       "      <td>655785</td>\n",
       "      <td>443953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154840</th>\n",
       "      <td>showi</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154841</th>\n",
       "      <td>gceap</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154842</th>\n",
       "      <td>neroc</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154843</th>\n",
       "      <td>hipep</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154844</th>\n",
       "      <td>glice</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154845 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  word_len  word_freq  n_articles\n",
       "0       which         5    1220752      890394\n",
       "1       first         5    1033698      751444\n",
       "2       known         5     742591      654233\n",
       "3       after         5     694687      537462\n",
       "4       their         5     655785      443953\n",
       "...       ...       ...        ...         ...\n",
       "154840  showi         5          2           2\n",
       "154841  gceap         5          2           1\n",
       "154842  neroc         5          2           1\n",
       "154843  hipep         5          2           1\n",
       "154844  glice         5          2           2\n",
       "\n",
       "[154845 rows x 4 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5459e01-8713-4ac4-a1e6-b43a13f74a83",
   "metadata": {},
   "source": [
    "## Prepare Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4cf8e6-7c7d-44d7-9a8b-d1848af67039",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_dict = {l: i for i, l in enumerate(list('abcdefghijklmnopqrstuvwxyz'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c4520c3-aae9-4e40-9594-0dc58547ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise solutions vector\n",
    "solutions = np.zeros((wordle_answers.shape[0], 26, 5), dtype='int8')\n",
    "for i, word in enumerate(wordle_answers.word):\n",
    "    for j, l in enumerate(word):\n",
    "        solutions[i, alpha_dict[l], j] = 1\n",
    "        \n",
    "candidates = np.zeros((wordle.shape[0], 26, 5), dtype='int8')\n",
    "for i, word in enumerate(wordle.word):\n",
    "    for j, l in enumerate(word):\n",
    "        candidates[i, alpha_dict[l], j] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c586369-af5f-4976-aac0-69e826034077",
   "metadata": {},
   "source": [
    "## Game Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7770d4-9ac9-4b66-836d-1210f6f93bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback(input_word, solution):\n",
    "    output = ''\n",
    "    for i in range(5):\n",
    "        if input_word[i] == solution[i]:\n",
    "            output += 'G'\n",
    "        elif input_word[i] in solution:\n",
    "            output += 'Y'\n",
    "        else:\n",
    "            output += 'X'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fda5f160-5378-4e6e-b566-229400f39fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wordset(input_word, feedback, wordset):\n",
    "    newset = wordset.copy()\n",
    "    for i in range(5):\n",
    "        if feedback[i] == 'G':\n",
    "            newset = newset.loc[newset.word.str[i] == input_word[i]]\n",
    "        elif feedback[i] == 'Y':\n",
    "            newset = newset.loc[newset.word.str.contains(input_word[i]) & newset.word.apply(lambda x: x[i] != input_word[i])]\n",
    "        else:\n",
    "            newset = newset.loc[~newset.word.str.contains(input_word[i])]\n",
    "    return newset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779dfd9c-9d44-4f00-8831-e0f78388f1b2",
   "metadata": {},
   "source": [
    "## Vector Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a99dbf-e831-4453-9b17-5a547702d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vec(word):\n",
    "    mat = np.zeros((26, 5), dtype='int8')\n",
    "    for i, l in enumerate(word):\n",
    "        mat[alpha_dict[l], i] = 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a150ed-a3e3-46ec-972d-309de010dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(word, solutions_masked):\n",
    "    word_vec = init_vec(word)\n",
    "    greens = solutions_masked * word_vec\n",
    "    yellows = word_vec * (\n",
    "        (solutions_masked.sum(axis=2) >= word_vec.sum(axis=1)) & \n",
    "        (word_vec.sum(axis=1) > 0)) \\\n",
    "        .reshape(solutions_masked.shape[0], 26, 1) - greens\n",
    "    greys = word_vec - greens - yellows\n",
    "    scores = np.array([np.sum(greens, axis=(1,2)), np.sum(yellows, axis=(1,2)), np.sum(greys, axis=(1,2))]).T\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e4c1447-69d4-46f5-966b-52766537e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_scores(word, solutions_masked):\n",
    "    scores = get_scores(word, solutions_masked)\n",
    "    df_scores = pd.DataFrame(scores, columns=['g', 'y', 'x'])\n",
    "    df_scores['score'] = df_scores.g * 2 + df_scores.y\n",
    "    \n",
    "    return df_scores.score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8883e64-f7e7-48d5-bf9c-870efc89777a",
   "metadata": {},
   "source": [
    "### Filter Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4fc40c1-16e2-4f5e-9366-4bb308fe412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_solution_mask():\n",
    "    return np.array([True] * wordle_answers.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e9f6e76-b66d-404e-858f-33ce3aa0b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_solution_mask(input_word, feedback, wordset, mask):\n",
    "    newmask = mask.copy()\n",
    "    for i in range(5):\n",
    "        if feedback[i] == 'G':\n",
    "            newmask[~wordset.word.str[i].eq(input_word[i])] = False\n",
    "        elif feedback[i] == 'Y':\n",
    "            newmask[~(wordset.word.str.contains(input_word[i]) & wordset.word.apply(lambda x: x[i] != input_word[i]))] = False\n",
    "        elif feedback[i] == 'X':\n",
    "            newmask[wordset.word.str.contains(input_word[i])] = False\n",
    "            \n",
    "    return newmask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a647ba-3e57-404e-8c69-3918524d8509",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Global Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a8c4ddd-0ff0-4313-8a35-90eb9eb87fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_letter_frequencies(wordset):\n",
    "    w = wordset.copy()\n",
    "    for letter in list('abcdefghijklmnopqrstuvwxyz'):\n",
    "        w[letter] = w.word.str.contains(letter).astype(int)\n",
    "    return w.iloc[:, 1:]\n",
    "\n",
    "def compute_score(x, freqs):\n",
    "    letters = set(x)\n",
    "    output = 0\n",
    "    for letter in letters:\n",
    "        output += freqs[letter]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "390fcb23-57d8-4953-a166-4ce9f5d1ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_freqs = compute_letter_frequencies(wordle).sum().to_dict()\n",
    "global_scores = wordle.word.apply(compute_score, freqs=global_freqs)\n",
    "global_scores = pd.DataFrame({'word': wordle.word, 'score': global_scores})\n",
    "global_scores = global_scores.merge(words_all[['word', 'word_freq', 'n_articles']], how='left', left_on='word', right_on='word')\n",
    "global_scores = global_scores.fillna(0).sort_values(['score', 'word_freq'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f05e4-71d8-4f01-91c5-0bd97b709323",
   "metadata": {},
   "source": [
    "## App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aca58ebd-b0c9-4aa3-afeb-c72121ec868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_app(pre_load=None):\n",
    "    \n",
    "    # Initialisation\n",
    "    candidate_list = wordle.copy()\n",
    "    solution_list = wordle_answers.copy()\n",
    "    solution_mask = init_solution_mask()\n",
    "    res = pd.DataFrame([{'a': 1}, {'a': 1}])\n",
    "    \n",
    "    step = 1\n",
    "    tested_words = []\n",
    "    all_chars = []\n",
    "    \n",
    "    while res.shape[0] > 1:\n",
    "        print(f'[ ---- STEP {step} ----]')\n",
    "        \n",
    "        # Get guess\n",
    "        if not (step == 1 and pre_load):\n",
    "            guess = input('Input a guess:')\n",
    "        else:\n",
    "            guess = pre_load\n",
    "        if guess.lower() in ['quit', 'q']:\n",
    "            return res\n",
    "        tested_words.append(guess)\n",
    "        all_chars = all_chars + list(set(guess))\n",
    "        all_chars = list(set(all_chars))\n",
    "        \n",
    "        # Get feedback\n",
    "        fb = input('Input feedback:')\n",
    "        if fb.lower() in ['quit', 'q']:\n",
    "            return res\n",
    "        \n",
    "        # Update solution mask and list\n",
    "        solution_mask = update_solution_mask(guess, fb.upper(), wordle_answers, solution_mask)\n",
    "        solution_list = filter_wordset(guess, fb.upper(), solution_list)\n",
    "        \n",
    "        # Compute scores\n",
    "        print(f'Evaluating all candidates. Running analysis...')\n",
    "        new_scores = Parallel(n_jobs=5, verbose=1)(delayed(get_final_scores)(word, solutions[solution_mask]) \\\n",
    "                                                   for word in tqdm(candidate_list.word))\n",
    "        \n",
    "        # Generate results\n",
    "        res = pd.DataFrame({'word': candidate_list.word, 'score': new_scores}) \\\n",
    "            .merge(words_all[['word', 'word_freq']], on='word', how='left') \\\n",
    "            .fillna(0)\n",
    "        \n",
    "        if solution_list.shape[0] > 0:        \n",
    "            print(f'Suggestions for step {step + 1}:')\n",
    "            display(res.sort_values(['score', 'word_freq'], ascending=False).head(10))\n",
    "        \n",
    "        if solution_list.shape[0] <= 10:\n",
    "            print(f'Small number of candidates remaining ({solution_list.shape[0]}). We recommend choosing the most popular option:')\n",
    "            res = res.loc[res.word.isin(solution_list.word)]\n",
    "            display(res.sort_values(['word_freq', 'score'], ascending=False).head(5))\n",
    "        \n",
    "        # Check for repeats\n",
    "        if solution_list.shape[0] <= 8 and solution_list.shape[0] >= 3:\n",
    "            w_copy = res.loc[res.word.isin(solution_list.word)].sort_values(['word_freq', 'score'], ascending=False).copy()\n",
    "            # Extract letters\n",
    "            for i in range(5):\n",
    "                w_copy[f'p{i}'] = w_copy.word.str[i]\n",
    "            \n",
    "            # Count the number of unique columns\n",
    "            unique_mask = w_copy.iloc[:, -5:].nunique() > 1\n",
    "            \n",
    "            # If only 1, then recommend another word\n",
    "            if unique_mask.sum() == 1:\n",
    "                wc = wordle.copy()\n",
    "                total_letters = w_copy.shape[0]\n",
    "                wc['scores'] = 0\n",
    "                wc['counts'] = 0\n",
    "                for i, letter in enumerate(np.squeeze(w_copy[unique_mask.index[unique_mask]].values)):\n",
    "                    wc['scores'] = wc['scores'] + (total_letters - i) * wc.word.str.contains(letter).astype(int)\n",
    "                    wc['counts'] = wc['counts'] + wc.word.str.contains(letter).astype(int)\n",
    "                    \n",
    "                print(f'\\nWords with only one letter differential detected. Consider filtering:')\n",
    "                display(wc.loc[wc.counts.le(total_letters // 2 * 3)].sort_values('scores', ascending=False).head(5))\n",
    "\n",
    "                \n",
    "        step += 1\n",
    "        print()\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657b7fb-2308-4068-8d89-fe128dc60f52",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d61a2f6-c918-480f-82d4-ef1c001b503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ---- STEP 1 ----]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input feedback: xxxyy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating all candidates. Running analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eea40b5965d4914bf6cd0559959fada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done 150 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions for step 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done 9062 out of 9071 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 9071 out of 9071 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>cider</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>citer</td>\n",
       "      <td>4.427350</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7414</th>\n",
       "      <td>diner</td>\n",
       "      <td>4.418803</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>tiler</td>\n",
       "      <td>4.410256</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3381</th>\n",
       "      <td>liter</td>\n",
       "      <td>4.401709</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>dicer</td>\n",
       "      <td>4.401709</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>niter</td>\n",
       "      <td>4.376068</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>diver</td>\n",
       "      <td>4.358974</td>\n",
       "      <td>3058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>finer</td>\n",
       "      <td>4.358974</td>\n",
       "      <td>681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8872</th>\n",
       "      <td>filer</td>\n",
       "      <td>4.358974</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     score  word_freq\n",
       "8123  cider  4.435897     1093.0\n",
       "1017  citer  4.427350       10.0\n",
       "7414  diner  4.418803     1125.0\n",
       "5849  tiler  4.410256       37.0\n",
       "3381  liter  4.401709      431.0\n",
       "1450  dicer  4.401709       62.0\n",
       "4016  niter  4.376068       49.0\n",
       "7661  diver  4.358974     3058.0\n",
       "6909  finer  4.358974      681.0\n",
       "8872  filer  4.358974       90.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ ---- STEP 2 ----]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input a guess: rider\n",
      "Input feedback: yxxgg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating all candidates. Running analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0a4abcd70f4368a4bc21946cee9c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done 150 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions for step 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done 9062 out of 9071 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 9071 out of 9071 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>tuber</td>\n",
       "      <td>5.208333</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>luter</td>\n",
       "      <td>5.208333</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>cuter</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>tuyer</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>buyer</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>1679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>bluer</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>cuber</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>upter</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>muter</td>\n",
       "      <td>5.041667</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>ulcer</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>438.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     score  word_freq\n",
       "7790  tuber  5.208333      394.0\n",
       "3511  luter  5.208333       45.0\n",
       "1301  cuter  5.125000       20.0\n",
       "6051  tuyer  5.125000        0.0\n",
       "7850  buyer  5.083333     1679.0\n",
       "7607  bluer  5.083333       43.0\n",
       "1262  cuber  5.083333       26.0\n",
       "6177  upter  5.083333        0.0\n",
       "3901  muter  5.041667       31.0\n",
       "6993  ulcer  5.000000      438.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ ---- STEP 3 ----]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input a guess: q\n"
     ]
    }
   ],
   "source": [
    "curr_res = run_app('soare')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d6af8-9a3c-4415-97cb-c3fbad26f98d",
   "metadata": {},
   "source": [
    "## Sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f45e0cf3-6bf8-4f84-bcc1-f9b6413030ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sim(input_word, solution):\n",
    "\n",
    "    # Initialisation\n",
    "    candidate_list = wordle.copy()\n",
    "    solution_list = wordle_answers.copy()\n",
    "    solution_mask = init_solution_mask()\n",
    "    res = pd.DataFrame([{'a': 1}, {'a': 1}])\n",
    "    \n",
    "    step = 1\n",
    "    tested_words = []\n",
    "    all_chars = []\n",
    "    ncands = []\n",
    "    \n",
    "    while res.shape[0] > 1:\n",
    "        # Get guess\n",
    "        if step == 1:\n",
    "            guess = input_word\n",
    "        tested_words.append(guess)\n",
    "        all_chars = all_chars + list(set(guess))\n",
    "        all_chars = list(set(all_chars))\n",
    "        \n",
    "        # Get feedback\n",
    "        fb = get_feedback(guess, solution)\n",
    "        \n",
    "        # Update solution mask and list\n",
    "        solution_mask = update_solution_mask(guess, fb.upper(), wordle_answers, solution_mask)\n",
    "        solution_list = filter_wordset(guess, fb.upper(), solution_list)\n",
    "        ncands.append(solution_list.shape[0])\n",
    "        # print(f'Step {step}: Guess: {guess} | Feedback: {fb} | Solutions: {solution_list.shape[0]}')\n",
    "        # Compute scores\n",
    "        new_scores = Parallel(n_jobs=5, verbose=0)(delayed(get_final_scores)(word, solutions[solution_mask]) \\\n",
    "                                                   for word in candidate_list.word)\n",
    "        \n",
    "        # Generate results\n",
    "        res = pd.DataFrame({'word': candidate_list.word, 'score': new_scores}) \\\n",
    "            .merge(words_all[['word', 'word_freq']], on='word', how='left') \\\n",
    "            .fillna(0)\n",
    "        \n",
    "        if solution_list.shape[0] > 10:     \n",
    "            # res = res.loc[res.word.isin(solution_list.word)]\n",
    "            guess = res.sort_values(['score', 'word_freq'], ascending=False).word.iloc[0]\n",
    "        \n",
    "        # For smaller solution sets\n",
    "        elif solution_list.shape[0] <= 10:\n",
    "            if solution_list.shape[0] <= 8 and solution_list.shape[0] >= 3:\n",
    "                w_copy = res.loc[res.word.isin(solution_list.word)].sort_values(['word_freq', 'score'], ascending=False).copy()\n",
    "                # Extract letters\n",
    "                for i in range(5):\n",
    "                    w_copy[f'p{i}'] = w_copy.word.str[i]\n",
    "\n",
    "                # Count the number of unique columns\n",
    "                unique_mask = w_copy.iloc[:, -5:].nunique() > 1\n",
    "\n",
    "                # If only 1, then recommend another word\n",
    "                if unique_mask.sum() == 1:\n",
    "                    wc = wordle.copy()\n",
    "                    total_letters = w_copy.shape[0]\n",
    "                    wc['scores'] = 0\n",
    "                    wc['counts'] = 0\n",
    "                    for i, letter in enumerate(np.squeeze(w_copy[unique_mask.index[unique_mask]].values)):\n",
    "                        wc['scores'] = wc['scores'] + (total_letters - i) * wc.word.str.contains(letter).astype(int)\n",
    "                        wc['counts'] = wc['counts'] + wc.word.str.contains(letter).astype(int)\n",
    "\n",
    "                    special_res = wc.loc[wc.counts.le(total_letters // 2 * 3)].sort_values('scores', ascending=False)\n",
    "                    guess = special_res.word.iloc[0]\n",
    "                else:\n",
    "                    res = res.loc[res.word.isin(solution_list.word)]\n",
    "                    guess = res.sort_values(['word_freq', 'score'], ascending=False).word.iloc[0]\n",
    "            else:\n",
    "                res = res.loc[res.word.isin(solution_list.word)]\n",
    "                guess = res.sort_values(['word_freq', 'score'], ascending=False).word.iloc[0]\n",
    "\n",
    "        if not fb.upper() == 'GGGGG':\n",
    "            step += 1\n",
    "        \n",
    "    return input_word, solution, step, ncands, tested_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "18382357-c7d1-4603-839b-706dd4fe7b84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f036e2e7f93c48569663f728f1092722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 10: serve | Min: 3 / Median: 4.0 / Mean: 4.0 / Max: 5\n",
      "Game 20: feign | Min: 2 / Median: 4.0 / Mean: 3.6315789473684212 / Max: 5\n",
      "Game 30: batty | Min: 2 / Median: 4.0 / Mean: 3.6206896551724137 / Max: 5\n",
      "Game 40: outdo | Min: 2 / Median: 4.0 / Mean: 3.717948717948718 / Max: 5\n",
      "Game 50: pound | Min: 2 / Median: 4.0 / Mean: 3.7346938775510203 / Max: 5\n",
      "Game 60: ivory | Min: 2 / Median: 4.0 / Mean: 3.76271186440678 / Max: 5\n",
      "Game 70: offal | Min: 2 / Median: 4.0 / Mean: 3.782608695652174 / Max: 6\n",
      "Game 80: front | Min: 2 / Median: 4.0 / Mean: 3.7341772151898733 / Max: 6\n",
      "Game 90: loopy | Min: 2 / Median: 4.0 / Mean: 3.730337078651685 / Max: 6\n",
      "Game 100: moult | Min: 2 / Median: 4.0 / Mean: 3.717171717171717 / Max: 6\n",
      "Game 110: guild | Min: 2 / Median: 4.0 / Mean: 3.7155963302752295 / Max: 6\n",
      "Game 120: dutch | Min: 2 / Median: 4.0 / Mean: 3.7478991596638656 / Max: 6\n",
      "Game 130: dozen | Min: 2 / Median: 4.0 / Mean: 3.744186046511628 / Max: 6\n",
      "Game 140: blurt | Min: 2 / Median: 4.0 / Mean: 3.7985611510791366 / Max: 6\n",
      "Game 150: gaudy | Min: 2 / Median: 4.0 / Mean: 3.791946308724832 / Max: 6\n",
      "Game 160: wrote | Min: 2 / Median: 4.0 / Mean: 3.79874213836478 / Max: 6\n",
      "Game 170: usher | Min: 2 / Median: 4.0 / Mean: 3.7633136094674557 / Max: 6\n",
      "Game 180: trace | Min: 2 / Median: 4.0 / Mean: 3.7653631284916202 / Max: 6\n",
      "Game 190: picky | Min: 2 / Median: 4.0 / Mean: 3.7777777777777777 / Max: 6\n",
      "Game 200: siege | Min: 2 / Median: 4.0 / Mean: 3.758793969849246 / Max: 6\n",
      "Game 210: tangy | Min: 2 / Median: 4.0 / Mean: 3.770334928229665 / Max: 6\n",
      "Game 220: knoll | Min: 2 / Median: 4.0 / Mean: 3.776255707762557 / Max: 6\n",
      "Game 230: shard | Min: 2 / Median: 4.0 / Mean: 3.7685589519650655 / Max: 6\n",
      "Game 240: robin | Min: 2 / Median: 4.0 / Mean: 3.7531380753138075 / Max: 6\n",
      "Game 250: other | Min: 2 / Median: 4.0 / Mean: 3.751004016064257 / Max: 6\n",
      "Game 260: mourn | Min: 2 / Median: 4.0 / Mean: 3.741312741312741 / Max: 6\n",
      "Game 270: focus | Min: 2 / Median: 4.0 / Mean: 3.7360594795539033 / Max: 6\n",
      "Game 280: slosh | Min: 2 / Median: 4.0 / Mean: 3.7240143369175627 / Max: 6\n",
      "Game 290: lowly | Min: 2 / Median: 4.0 / Mean: 3.7231833910034604 / Max: 6\n",
      "Game 300: stair | Min: 2 / Median: 4.0 / Mean: 3.729096989966555 / Max: 6\n",
      "Game 310: flair | Min: 2 / Median: 4.0 / Mean: 3.705501618122977 / Max: 6\n",
      "Game 320: zesty | Min: 2 / Median: 4.0 / Mean: 3.70846394984326 / Max: 7\n",
      "Game 330: badge | Min: 2 / Median: 4.0 / Mean: 3.7142857142857144 / Max: 7\n",
      "Game 340: delve | Min: 2 / Median: 4.0 / Mean: 3.7168141592920354 / Max: 7\n",
      "Game 350: asset | Min: 2 / Median: 4.0 / Mean: 3.71919770773639 / Max: 7\n",
      "Game 360: depth | Min: 2 / Median: 4.0 / Mean: 3.7075208913649025 / Max: 7\n",
      "Game 370: atone | Min: 2 / Median: 4.0 / Mean: 3.7154471544715446 / Max: 7\n",
      "Game 380: smite | Min: 2 / Median: 4.0 / Mean: 3.712401055408971 / Max: 7\n",
      "Game 390: lilac | Min: 2 / Median: 4.0 / Mean: 3.7249357326478147 / Max: 7\n",
      "Game 400: stalk | Min: 2 / Median: 4.0 / Mean: 3.724310776942356 / Max: 7\n",
      "Game 410: flock | Min: 2 / Median: 4.0 / Mean: 3.728606356968215 / Max: 7\n",
      "Game 420: motto | Min: 2 / Median: 4.0 / Mean: 3.739856801909308 / Max: 7\n",
      "Game 430: alien | Min: 2 / Median: 4.0 / Mean: 3.745920745920746 / Max: 7\n",
      "Game 440: gruel | Min: 2 / Median: 4.0 / Mean: 3.7494305239179955 / Max: 7\n",
      "Game 450: needy | Min: 2 / Median: 4.0 / Mean: 3.750556792873051 / Max: 7\n",
      "Game 460: charm | Min: 2 / Median: 4.0 / Mean: 3.7516339869281046 / Max: 7\n",
      "Game 470: booze | Min: 2 / Median: 4.0 / Mean: 3.7590618336886994 / Max: 7\n",
      "Game 480: sooth | Min: 2 / Median: 4.0 / Mean: 3.7640918580375784 / Max: 7\n",
      "Game 490: scald | Min: 2 / Median: 4.0 / Mean: 3.7607361963190185 / Max: 7\n",
      "Game 500: howdy | Min: 2 / Median: 4.0 / Mean: 3.7635270541082164 / Max: 7\n",
      "Game 510: exist | Min: 2 / Median: 4.0 / Mean: 3.764243614931238 / Max: 7\n",
      "Game 520: sneak | Min: 2 / Median: 4.0 / Mean: 3.7591522157996144 / Max: 7\n",
      "Game 530: vomit | Min: 2 / Median: 4.0 / Mean: 3.7580340264650283 / Max: 7\n",
      "Game 540: spell | Min: 2 / Median: 4.0 / Mean: 3.7606679035250465 / Max: 7\n",
      "Game 550: shock | Min: 2 / Median: 4.0 / Mean: 3.7650273224043715 / Max: 7\n",
      "Game 560: quasi | Min: 2 / Median: 4.0 / Mean: 3.7656529516994635 / Max: 7\n",
      "Game 570: plume | Min: 2 / Median: 4.0 / Mean: 3.7627416520210897 / Max: 7\n",
      "Game 580: safer | Min: 2 / Median: 4.0 / Mean: 3.761658031088083 / Max: 7\n",
      "Game 590: gusty | Min: 2 / Median: 4.0 / Mean: 3.7589134125636674 / Max: 7\n",
      "Game 600: stray | Min: 2 / Median: 4.0 / Mean: 3.7529215358931554 / Max: 7\n",
      "Game 610: leaky | Min: 2 / Median: 4.0 / Mean: 3.7471264367816093 / Max: 7\n",
      "Game 620: sheen | Min: 2 / Median: 4.0 / Mean: 3.7479806138933762 / Max: 7\n",
      "Game 630: price | Min: 2 / Median: 4.0 / Mean: 3.737678855325914 / Max: 7\n",
      "Game 640: niece | Min: 2 / Median: 4.0 / Mean: 3.7417840375586855 / Max: 7\n",
      "Game 650: angle | Min: 2 / Median: 4.0 / Mean: 3.7442218798151004 / Max: 7\n",
      "Game 660: arson | Min: 2 / Median: 4.0 / Mean: 3.7420333839150226 / Max: 7\n",
      "Game 670: lance | Min: 2 / Median: 4.0 / Mean: 3.7443946188340806 / Max: 7\n",
      "Game 680: frown | Min: 2 / Median: 4.0 / Mean: 3.7422680412371134 / Max: 7\n",
      "Game 690: gusto | Min: 2 / Median: 4.0 / Mean: 3.741654571843251 / Max: 7\n",
      "Game 700: venom | Min: 2 / Median: 4.0 / Mean: 3.7453505007153076 / Max: 7\n",
      "Game 710: awoke | Min: 2 / Median: 4.0 / Mean: 3.744710860366714 / Max: 7\n",
      "Game 720: lunar | Min: 2 / Median: 4.0 / Mean: 3.7468706536856744 / Max: 7\n",
      "Game 730: savvy | Min: 2 / Median: 4.0 / Mean: 3.7434842249657065 / Max: 7\n",
      "Game 740: cycle | Min: 2 / Median: 4.0 / Mean: 3.7483085250338295 / Max: 7\n",
      "Game 750: blink | Min: 2 / Median: 4.0 / Mean: 3.746328437917223 / Max: 7\n",
      "Game 760: shaft | Min: 2 / Median: 4.0 / Mean: 3.7496706192358364 / Max: 7\n",
      "Game 770: rigor | Min: 2 / Median: 4.0 / Mean: 3.741222366710013 / Max: 7\n",
      "Game 780: dowdy | Min: 2 / Median: 4.0 / Mean: 3.7445442875481385 / Max: 7\n",
      "Game 790: splat | Min: 2 / Median: 4.0 / Mean: 3.7427122940430926 / Max: 7\n",
      "Game 800: queue | Min: 2 / Median: 4.0 / Mean: 3.737171464330413 / Max: 7\n",
      "Game 810: eaten | Min: 2 / Median: 4.0 / Mean: 3.734239802224969 / Max: 7\n",
      "Game 820: dying | Min: 2 / Median: 4.0 / Mean: 3.735042735042735 / Max: 7\n",
      "Game 830: crowd | Min: 2 / Median: 4.0 / Mean: 3.738238841978287 / Max: 7\n",
      "Game 840: ruler | Min: 2 / Median: 4.0 / Mean: 3.740166865315852 / Max: 7\n",
      "Game 850: barge | Min: 2 / Median: 4.0 / Mean: 3.736160188457008 / Max: 7\n",
      "Game 860: begun | Min: 2 / Median: 4.0 / Mean: 3.7403958090803258 / Max: 7\n",
      "Game 870: assay | Min: 2 / Median: 4.0 / Mean: 3.7387802071346377 / Max: 7\n",
      "Game 880: smack | Min: 2 / Median: 4.0 / Mean: 3.737201365187713 / Max: 7\n",
      "Game 890: vista | Min: 2 / Median: 4.0 / Mean: 3.737907761529809 / Max: 7\n",
      "Game 900: eight | Min: 2 / Median: 4.0 / Mean: 3.7374860956618465 / Max: 7\n",
      "Game 910: alley | Min: 2 / Median: 4.0 / Mean: 3.7337733773377337 / Max: 7\n",
      "Game 920: stood | Min: 2 / Median: 4.0 / Mean: 3.7290533188248096 / Max: 7\n",
      "Game 930: sieve | Min: 2 / Median: 4.0 / Mean: 3.7308934337997846 / Max: 7\n",
      "Game 940: strut | Min: 2 / Median: 4.0 / Mean: 3.730564430244941 / Max: 7\n",
      "Game 950: shoal | Min: 2 / Median: 4.0 / Mean: 3.731296101159115 / Max: 7\n",
      "Game 960: elect | Min: 2 / Median: 4.0 / Mean: 3.7288842544316996 / Max: 7\n",
      "Game 970: gavel | Min: 2 / Median: 4.0 / Mean: 3.7285861713106296 / Max: 7\n",
      "Game 980: cabin | Min: 2 / Median: 4.0 / Mean: 3.734422880490296 / Max: 7\n",
      "Game 990: child | Min: 2 / Median: 4.0 / Mean: 3.732052578361982 / Max: 7\n",
      "Game 1000: steal | Min: 2 / Median: 4.0 / Mean: 3.734734734734735 / Max: 7\n",
      "Game 1010: otter | Min: 2 / Median: 4.0 / Mean: 3.7314172447968286 / Max: 7\n",
      "Game 1020: slimy | Min: 2 / Median: 4.0 / Mean: 3.7311089303238467 / Max: 7\n",
      "Game 1030: reign | Min: 2 / Median: 4.0 / Mean: 3.728862973760933 / Max: 7\n",
      "Game 1040: shank | Min: 2 / Median: 4.0 / Mean: 3.7295476419634266 / Max: 7\n",
      "Game 1050: rabbi | Min: 2 / Median: 4.0 / Mean: 3.726406101048618 / Max: 7\n",
      "Game 1060: crown | Min: 2 / Median: 4.0 / Mean: 3.728989612842304 / Max: 7\n",
      "Game 1070: amass | Min: 2 / Median: 4.0 / Mean: 3.7268475210477083 / Max: 7\n",
      "Game 1080: beach | Min: 2 / Median: 4.0 / Mean: 3.726598702502317 / Max: 7\n",
      "Game 1090: drunk | Min: 2 / Median: 4.0 / Mean: 3.7254361799816347 / Max: 7\n",
      "Game 1100: worry | Min: 2 / Median: 4.0 / Mean: 3.7279344858962693 / Max: 7\n",
      "Game 1110: adorn | Min: 2 / Median: 4.0 / Mean: 3.72678088367899 / Max: 7\n",
      "Game 1120: emcee | Min: 2 / Median: 4.0 / Mean: 3.7256478999106344 / Max: 7\n",
      "Game 1130: sweat | Min: 2 / Median: 4.0 / Mean: 3.7271922054915856 / Max: 7\n",
      "Game 1140: align | Min: 2 / Median: 4.0 / Mean: 3.7251975417032486 / Max: 7\n",
      "Game 1150: dryer | Min: 2 / Median: 4.0 / Mean: 3.7275892080069624 / Max: 7\n",
      "Game 1160: bonus | Min: 2 / Median: 4.0 / Mean: 3.729939603106126 / Max: 7\n",
      "Game 1170: rearm | Min: 2 / Median: 4.0 / Mean: 3.730538922155689 / Max: 7\n",
      "Game 1180: usage | Min: 2 / Median: 4.0 / Mean: 3.7311280746395252 / Max: 7\n",
      "Game 1190: swath | Min: 2 / Median: 4.0 / Mean: 3.731707317073171 / Max: 7\n",
      "Game 1200: canon | Min: 2 / Median: 4.0 / Mean: 3.7289407839866557 / Max: 7\n",
      "Game 1210: puppy | Min: 2 / Median: 4.0 / Mean: 3.727047146401985 / Max: 7\n",
      "Game 1220: topaz | Min: 2 / Median: 4.0 / Mean: 3.7284659557013944 / Max: 7\n",
      "Game 1230: jumbo | Min: 2 / Median: 4.0 / Mean: 3.729048006509357 / Max: 7\n",
      "Game 1240: tempo | Min: 2 / Median: 4.0 / Mean: 3.7288135593220337 / Max: 7\n",
      "Game 1250: dwell | Min: 2 / Median: 4.0 / Mean: 3.7261809447558045 / Max: 7\n",
      "Game 1260: mammy | Min: 2 / Median: 4.0 / Mean: 3.72835583796664 / Max: 7\n",
      "Game 1270: skate | Min: 2 / Median: 4.0 / Mean: 3.7297084318360914 / Max: 7\n",
      "Game 1280: nadir | Min: 2 / Median: 4.0 / Mean: 3.72869429241595 / Max: 7\n",
      "Game 1290: oaken | Min: 2 / Median: 4.0 / Mean: 3.7276958882854925 / Max: 7\n",
      "Game 1300: rocky | Min: 2 / Median: 4.0 / Mean: 3.7282525019245574 / Max: 7\n",
      "Game 1310: uncle | Min: 2 / Median: 4.0 / Mean: 3.72498090145149 / Max: 7\n",
      "Game 1320: bleak | Min: 2 / Median: 4.0 / Mean: 3.7247915087187264 / Max: 7\n",
      "Game 1330: cumin | Min: 2 / Median: 4.0 / Mean: 3.727614747930775 / Max: 7\n",
      "Game 1340: deign | Min: 2 / Median: 4.0 / Mean: 3.7303958177744585 / Max: 7\n",
      "Game 1350: shoot | Min: 2 / Median: 4.0 / Mean: 3.733135656041512 / Max: 7\n",
      "Game 1360: fiery | Min: 2 / Median: 4.0 / Mean: 3.7328918322295808 / Max: 7\n",
      "Game 1370: duvet | Min: 2 / Median: 4.0 / Mean: 3.7304601899196492 / Max: 7\n",
      "Game 1380: empty | Min: 2 / Median: 4.0 / Mean: 3.732414793328499 / Max: 7\n",
      "Game 1390: shaky | Min: 2 / Median: 4.0 / Mean: 3.7314614830813535 / Max: 7\n",
      "Game 1400: shrew | Min: 2 / Median: 4.0 / Mean: 3.7305218012866335 / Max: 7\n",
      "Game 1410: beefy | Min: 2 / Median: 4.0 / Mean: 3.729595457771469 / Max: 7\n",
      "Game 1420: toast | Min: 2 / Median: 4.0 / Mean: 3.730091613812544 / Max: 7\n",
      "Game 1430: skull | Min: 2 / Median: 4.0 / Mean: 3.728481455563331 / Max: 7\n",
      "Game 1440: latch | Min: 2 / Median: 4.0 / Mean: 3.7268936761640026 / Max: 7\n",
      "Game 1450: defer | Min: 2 / Median: 4.0 / Mean: 3.7294685990338166 / Max: 7\n",
      "Game 1460: obese | Min: 2 / Median: 4.0 / Mean: 3.7258396161754628 / Max: 7\n",
      "Game 1470: tidal | Min: 2 / Median: 4.0 / Mean: 3.7263444520081688 / Max: 7\n",
      "Game 1480: whale | Min: 2 / Median: 4.0 / Mean: 3.72684246112238 / Max: 7\n",
      "Game 1490: suave | Min: 2 / Median: 4.0 / Mean: 3.7246474143720616 / Max: 7\n",
      "Game 1500: plaid | Min: 2 / Median: 4.0 / Mean: 3.724482988659106 / Max: 7\n",
      "Game 1510: gazer | Min: 2 / Median: 4.0 / Mean: 3.72233267064281 / Max: 7\n",
      "Game 1520: these | Min: 2 / Median: 4.0 / Mean: 3.7235023041474653 / Max: 7\n",
      "Game 1530: chick | Min: 2 / Median: 4.0 / Mean: 3.7253106605624593 / Max: 7\n",
      "Game 1540: wield | Min: 2 / Median: 4.0 / Mean: 3.7251461988304095 / Max: 7\n",
      "Game 1550: glade | Min: 2 / Median: 4.0 / Mean: 3.724983860555197 / Max: 7\n",
      "Game 1560: table | Min: 2 / Median: 4.0 / Mean: 3.725465041693393 / Max: 7\n",
      "Game 1570: pixel | Min: 2 / Median: 4.0 / Mean: 3.7240280433397066 / Max: 7\n",
      "Game 1580: leash | Min: 2 / Median: 4.0 / Mean: 3.7238758708043065 / Max: 7\n",
      "Game 1590: audio | Min: 2 / Median: 4.0 / Mean: 3.720578980490875 / Max: 7\n",
      "Game 1600: early | Min: 2 / Median: 4.0 / Mean: 3.720450281425891 / Max: 7\n",
      "Game 1610: salsa | Min: 2 / Median: 4.0 / Mean: 3.722809198259789 / Max: 7\n",
      "Game 1620: force | Min: 2 / Median: 4.0 / Mean: 3.7220506485484868 / Max: 7\n",
      "Game 1630: clash | Min: 2 / Median: 4.0 / Mean: 3.7213014119091468 / Max: 7\n",
      "Game 1640: sewer | Min: 2 / Median: 4.0 / Mean: 3.7181208053691277 / Max: 7\n",
      "Game 1650: fuzzy | Min: 2 / Median: 4.0 / Mean: 3.7174044875682233 / Max: 7\n",
      "Game 1660: skiff | Min: 2 / Median: 4.0 / Mean: 3.719107896323086 / Max: 7\n",
      "Game 1670: wrack | Min: 2 / Median: 4.0 / Mean: 3.718993409227082 / Max: 7\n",
      "Game 1680: climb | Min: 2 / Median: 4.0 / Mean: 3.718880285884455 / Max: 7\n",
      "Game 1690: hilly | Min: 2 / Median: 4.0 / Mean: 3.718768502072232 / Max: 7\n",
      "Game 1700: quest | Min: 2 / Median: 4.0 / Mean: 3.7151265450264863 / Max: 7\n",
      "Game 1710: broad | Min: 2 / Median: 4.0 / Mean: 3.7150380339379754 / Max: 7\n",
      "Game 1720: taste | Min: 2 / Median: 4.0 / Mean: 3.7137870855148343 / Max: 7\n",
      "Game 1730: crane | Min: 2 / Median: 4.0 / Mean: 3.7137073452862928 / Max: 7\n",
      "Game 1740: jazzy | Min: 2 / Median: 4.0 / Mean: 3.714203565267395 / Max: 7\n",
      "Game 1750: small | Min: 2 / Median: 4.0 / Mean: 3.713550600343053 / Max: 7\n",
      "Game 1760: owing | Min: 2 / Median: 4.0 / Mean: 3.7129050596930075 / Max: 7\n",
      "Game 1770: melon | Min: 2 / Median: 4.0 / Mean: 3.7133973996608254 / Max: 7\n",
      "Game 1780: birth | Min: 2 / Median: 4.0 / Mean: 3.712759977515458 / Max: 7\n",
      "Game 1790: uncut | Min: 2 / Median: 4.0 / Mean: 3.7110117384013415 / Max: 7\n",
      "Game 1800: ditch | Min: 2 / Median: 4.0 / Mean: 3.709838799332963 / Max: 7\n",
      "Game 1810: chart | Min: 2 / Median: 4.0 / Mean: 3.7097844112769485 / Max: 7\n",
      "Game 1820: foamy | Min: 2 / Median: 4.0 / Mean: 3.708081363386476 / Max: 7\n",
      "Game 1830: krill | Min: 2 / Median: 4.0 / Mean: 3.7091306724986333 / Max: 7\n",
      "Game 1840: phone | Min: 2 / Median: 4.0 / Mean: 3.7096247960848285 / Max: 7\n",
      "Game 1850: fetal | Min: 2 / Median: 4.0 / Mean: 3.707950243374797 / Max: 7\n",
      "Game 1860: trend | Min: 2 / Median: 4.0 / Mean: 3.7089833243679395 / Max: 7\n",
      "Game 1870: fever | Min: 2 / Median: 4.0 / Mean: 3.7084002140181918 / Max: 7\n",
      "Game 1880: wafer | Min: 2 / Median: 4.0 / Mean: 3.7104843001596595 / Max: 7\n",
      "Game 1890: motel | Min: 2 / Median: 4.0 / Mean: 3.7114875595553203 / Max: 7\n",
      "Game 1900: anode | Min: 2 / Median: 4.0 / Mean: 3.712480252764613 / Max: 7\n",
      "Game 1910: video | Min: 2 / Median: 4.0 / Mean: 3.713462545835516 / Max: 7\n",
      "Game 1920: plaza | Min: 2 / Median: 4.0 / Mean: 3.71235018238666 / Max: 7\n",
      "Game 1930: raspy | Min: 2 / Median: 4.0 / Mean: 3.711249351995853 / Max: 7\n",
      "Game 1940: wrath | Min: 2 / Median: 4.0 / Mean: 3.7106756059824653 / Max: 7\n",
      "Game 1950: nylon | Min: 2 / Median: 4.0 / Mean: 3.711133914828117 / Max: 7\n",
      "Game 1960: leggy | Min: 2 / Median: 4.0 / Mean: 3.7131189382337926 / Max: 7\n",
      "Game 1970: gross | Min: 2 / Median: 4.0 / Mean: 3.713560182833926 / Max: 7\n",
      "Game 1980: giddy | Min: 2 / Median: 4.0 / Mean: 3.715007579585649 / Max: 7\n",
      "Game 1990: noise | Min: 2 / Median: 4.0 / Mean: 3.715937657114128 / Max: 7\n",
      "Game 2000: white | Min: 2 / Median: 4.0 / Mean: 3.7158579289644824 / Max: 7\n",
      "Game 2010: surge | Min: 2 / Median: 4.0 / Mean: 3.714783474365356 / Max: 7\n",
      "Game 2020: spiky | Min: 2 / Median: 4.0 / Mean: 3.7161961367013374 / Max: 7\n",
      "Game 2030: lumen | Min: 2 / Median: 4.0 / Mean: 3.716116313454904 / Max: 7\n",
      "Game 2040: affix | Min: 2 / Median: 4.0 / Mean: 3.7184894556154977 / Max: 8\n",
      "Game 2050: quail | Min: 2 / Median: 4.0 / Mean: 3.7198633479746217 / Max: 8\n",
      "Game 2060: bison | Min: 2 / Median: 4.0 / Mean: 3.718795531811559 / Max: 8\n",
      "Game 2070: endow | Min: 2 / Median: 4.0 / Mean: 3.72208796520058 / Max: 8\n",
      "Game 2080: leech | Min: 2 / Median: 4.0 / Mean: 3.721981721981722 / Max: 8\n",
      "Game 2090: biddy | Min: 2 / Median: 4.0 / Mean: 3.719961704164672 / Max: 8\n",
      "Game 2100: truck | Min: 2 / Median: 4.0 / Mean: 3.722248689852311 / Max: 8\n",
      "Game 2110: banjo | Min: 2 / Median: 4.0 / Mean: 3.7197724039829305 / Max: 8\n",
      "Game 2120: pubic | Min: 2 / Median: 4.0 / Mean: 3.7215667767815006 / Max: 8\n",
      "Game 2130: hurry | Min: 2 / Median: 4.0 / Mean: 3.7228745890089243 / Max: 8\n",
      "Game 2140: newer | Min: 2 / Median: 4.0 / Mean: 3.7232351566152406 / Max: 8\n",
      "Game 2150: lorry | Min: 2 / Median: 4.0 / Mean: 3.7235923685435086 / Max: 8\n",
      "Game 2160: crony | Min: 2 / Median: 4.0 / Mean: 3.7230199166280684 / Max: 8\n",
      "Game 2170: bunch | Min: 2 / Median: 4.0 / Mean: 3.7266021207929922 / Max: 8\n",
      "Game 2180: magma | Min: 2 / Median: 4.0 / Mean: 3.7273978889398807 / Max: 8\n",
      "Game 2190: clang | Min: 2 / Median: 4.0 / Mean: 3.724988579259936 / Max: 8\n",
      "Game 2200: folio | Min: 2 / Median: 4.0 / Mean: 3.7235106866757617 / Max: 8\n",
      "Game 2210: guava | Min: 2 / Median: 4.0 / Mean: 3.7229515617926663 / Max: 8\n",
      "Game 2220: plait | Min: 2 / Median: 4.0 / Mean: 3.7242000901306893 / Max: 8\n",
      "Game 2230: junta | Min: 2 / Median: 4.0 / Mean: 3.725437415881561 / Max: 8\n",
      "Game 2240: speak | Min: 2 / Median: 4.0 / Mean: 3.72532380527021 / Max: 8\n",
      "Game 2250: teddy | Min: 2 / Median: 4.0 / Mean: 3.726989773232548 / Max: 8\n",
      "Game 2260: clump | Min: 2 / Median: 4.0 / Mean: 3.7250996015936253 / Max: 8\n",
      "Game 2270: basal | Min: 2 / Median: 4.0 / Mean: 3.7249889819303657 / Max: 8\n",
      "Game 2280: hello | Min: 2 / Median: 4.0 / Mean: 3.7253181219833262 / Max: 8\n",
      "Game 2290: rayon | Min: 2 / Median: 4.0 / Mean: 3.72695500218436 / Max: 8\n",
      "Game 2300: peace | Min: 2 / Median: 4.0 / Mean: 3.7250978686385383 / Max: 8\n",
      "Game 2310: adult | Min: 2 / Median: 4.0 / Mean: 3.7245560848852315 / Max: 8\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "results = []\n",
    "main_word = 'soare'\n",
    "\n",
    "for word in tqdm(wordle_answers.word):\n",
    "    if counter % 10 == 0:\n",
    "        temp_df = pd.DataFrame(results, columns=['word', 'solution', 'steps', 'ncands', 'tested_words'])\n",
    "        print(f'Game {counter}: {word} | Min: {temp_df.steps.min()} / Median: {temp_df.steps.median()} / Mean: {temp_df.steps.mean()} / Max: {temp_df.steps.max()}')\n",
    "    \n",
    "    results.append(run_sim(main_word, word))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b4520da1-275f-4764-942d-23f14eb923f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['word', 'solution', 'steps', 'ncands', 'tested_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ccc93357-3dd0-4cbb-aee6-5d720dd57a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    942\n",
       "3    873\n",
       "5    323\n",
       "2    113\n",
       "6     56\n",
       "7      7\n",
       "8      1\n",
       "Name: steps, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4    0.406911\n",
       "3    0.377106\n",
       "5    0.139525\n",
       "2    0.048812\n",
       "6    0.024190\n",
       "7    0.003024\n",
       "8    0.000432\n",
       "Name: steps, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.steps.value_counts())\n",
    "display(df.steps.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3001e3f5-cdd5-45ea-bf66-19fb85fa617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2315.000000\n",
       "mean        3.723974\n",
       "std         0.875731\n",
       "min         2.000000\n",
       "25%         3.000000\n",
       "50%         4.000000\n",
       "75%         4.000000\n",
       "max         8.000000\n",
       "Name: steps, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.steps.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "166ca899-a3b1-4695-b5fc-6ec7087735c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>solution</th>\n",
       "      <th>steps</th>\n",
       "      <th>ncands</th>\n",
       "      <th>tested_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>soare</td>\n",
       "      <td>foyer</td>\n",
       "      <td>7</td>\n",
       "      <td>[22, 8, 6, 5, 3, 2, 1]</td>\n",
       "      <td>[soare, vower, roger, boxer, poker, homer, foyer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>soare</td>\n",
       "      <td>gawky</td>\n",
       "      <td>7</td>\n",
       "      <td>[138, 16, 4, 3, 2, 1]</td>\n",
       "      <td>[soare, canty, badly, happy, jazzy, mammy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>soare</td>\n",
       "      <td>ember</td>\n",
       "      <td>7</td>\n",
       "      <td>[117, 23, 8, 3, 2, 1]</td>\n",
       "      <td>[soare, cider, luter, never, hyper, freer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>soare</td>\n",
       "      <td>riper</td>\n",
       "      <td>7</td>\n",
       "      <td>[117, 14, 6, 4, 2, 1]</td>\n",
       "      <td>[soare, cider, fiver, tiger, liner, piper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>soare</td>\n",
       "      <td>waver</td>\n",
       "      <td>7</td>\n",
       "      <td>[61, 15, 6, 4, 2, 1]</td>\n",
       "      <td>[soare, later, pager, baker, racer, wafer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>soare</td>\n",
       "      <td>sappy</td>\n",
       "      <td>7</td>\n",
       "      <td>[19, 5, 4, 3, 2, 1]</td>\n",
       "      <td>[soare, salty, sandy, savvy, sassy, saucy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>soare</td>\n",
       "      <td>corer</td>\n",
       "      <td>8</td>\n",
       "      <td>[22, 8, 6, 5, 3, 2, 1]</td>\n",
       "      <td>[soare, vower, roger, boxer, poker, homer, foyer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>soare</td>\n",
       "      <td>vaunt</td>\n",
       "      <td>7</td>\n",
       "      <td>[138, 10, 6, 3, 2, 1]</td>\n",
       "      <td>[soare, canty, paint, dight, jetty, taunt]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word solution  steps                  ncands  \\\n",
       "310   soare    foyer      7  [22, 8, 6, 5, 3, 2, 1]   \n",
       "384   soare    gawky      7   [138, 16, 4, 3, 2, 1]   \n",
       "1376  soare    ember      7   [117, 23, 8, 3, 2, 1]   \n",
       "1553  soare    riper      7   [117, 14, 6, 4, 2, 1]   \n",
       "1870  soare    waver      7    [61, 15, 6, 4, 2, 1]   \n",
       "2015  soare    sappy      7     [19, 5, 4, 3, 2, 1]   \n",
       "2036  soare    corer      8  [22, 8, 6, 5, 3, 2, 1]   \n",
       "2280  soare    vaunt      7   [138, 10, 6, 3, 2, 1]   \n",
       "\n",
       "                                           tested_words  \n",
       "310   [soare, vower, roger, boxer, poker, homer, foyer]  \n",
       "384          [soare, canty, badly, happy, jazzy, mammy]  \n",
       "1376         [soare, cider, luter, never, hyper, freer]  \n",
       "1553         [soare, cider, fiver, tiger, liner, piper]  \n",
       "1870         [soare, later, pager, baker, racer, wafer]  \n",
       "2015         [soare, salty, sandy, savvy, sassy, saucy]  \n",
       "2036  [soare, vower, roger, boxer, poker, homer, foyer]  \n",
       "2280         [soare, canty, paint, dight, jetty, taunt]  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.steps >= 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce603faa-ea43-4b0b-ab00-6b38983cba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/bf_soare.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a6b20e-63ed-4670-8c9d-9367a23d0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "test1 = []\n",
    "main_word = 'soare'\n",
    "\n",
    "for word in tqdm(wordle_answers.word):\n",
    "    if counter % 10 == 0:\n",
    "        temp_df = pd.DataFrame(results, columns=['word', 'solution', 'steps', 'ncands', 'tested_words'])\n",
    "        print(f'Game {counter}: {word} | Min: {temp_df.steps.min()} / Median: {temp_df.steps.median()} / Mean: {temp_df.steps.mean()} / Max: {temp_df.steps.max()}')\n",
    "    \n",
    "    test1.append(run_sim(main_word, word))\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
