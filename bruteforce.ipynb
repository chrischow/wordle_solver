{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc3de08-88be-469e-b666-9f43457246c4",
   "metadata": {},
   "source": [
    "# Brute Force with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9663d273-9e91-4410-a674-7996d3f970a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a9b42-87a4-4875-b94d-ae25c967c174",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3190d2c3-b54e-4c03-b528-0dc85a1f0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wordle-candidates.json', 'r') as file:\n",
    "    wordle_candidates = json.load(file)\n",
    "    \n",
    "with open('data/wordle-answers.json', 'r') as file:\n",
    "    wordle_answers = json.load(file)\n",
    "\n",
    "wordle_candidates = pd.DataFrame(wordle_candidates['words'], columns=['word'])\n",
    "wordle_answers = pd.DataFrame(wordle_answers['words'], columns=['word'])\n",
    "wordle_candidates['is_answer'] = 0\n",
    "wordle_answers['is_answer'] = 1\n",
    "wordle = wordle_candidates.append(wordle_answers).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4273010f-6e69-4305-9c65-35216873bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_all = pd.read_table('data/archive/en_words_1_5-5.txt', delimiter=' ', header=None, index_col=None,\n",
    "                         names=['word_len', 'word_freq', 'n_articles']).reset_index()\n",
    "words_all = words_all.rename(columns={'index': 'word'})\n",
    "\n",
    "# Filter by english\n",
    "alphabet = list('abcdefghijklmnopqrstuvwxyz')\n",
    "words_all = words_all.loc[words_all.word.apply(lambda x: all([l in alphabet for l in x]))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5459e01-8713-4ac4-a1e6-b43a13f74a83",
   "metadata": {},
   "source": [
    "## Prepare Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4cf8e6-7c7d-44d7-9a8b-d1848af67039",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_dict = {l: i for i, l in enumerate(list('abcdefghijklmnopqrstuvwxyz'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4520c3-aae9-4e40-9594-0dc58547ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise solutions vector\n",
    "solutions = np.zeros((wordle.shape[0], 26, 5))\n",
    "for i, word in enumerate(wordle.word):\n",
    "    for j, l in enumerate(word):\n",
    "        solutions[i, alpha_dict[l], j] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c586369-af5f-4976-aac0-69e826034077",
   "metadata": {},
   "source": [
    "## Game Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7770d4-9ac9-4b66-836d-1210f6f93bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback(input_word, solution):\n",
    "    output = ''\n",
    "    for i in range(5):\n",
    "        if input_word[i] == solution[i]:\n",
    "            output += 'G'\n",
    "        elif input_word[i] in solution:\n",
    "            output += 'Y'\n",
    "        else:\n",
    "            output += 'X'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda5f160-5378-4e6e-b566-229400f39fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wordset(input_word, feedback, wordset):\n",
    "    newset = wordset.copy()\n",
    "    for i in range(5):\n",
    "        if feedback[i] == 'G':\n",
    "            newset = newset.loc[newset.word.str[i] == input_word[i]]\n",
    "        elif feedback[i] == 'Y':\n",
    "            # newset = newset.loc[newset.word.str.contains(input_word[i])]\n",
    "            newset = newset.loc[newset.word.str.contains(input_word[i]) & newset.word.apply(lambda x: x[i] != input_word[i])]\n",
    "        else:\n",
    "            newset = newset.loc[~newset.word.str.contains(input_word[i])]\n",
    "    return newset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7597621a-f6d3-4842-b3b6-0b67175548bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncands = []\n",
    "# mod_greens = np.where((greens.sum(axis=-2) == 0).reshape((np.sum(mask), 1, 5)), np.ones((np.sum(mask),26,1)), greens)\n",
    "# mod_yellows = yellows[i].sum(axis=-1)>= solutions[mask]\n",
    "# mod_greys = 1 - np.where(greys.sum(axis=-1).reshape((np.sum(mask),26, 1)) >= 1, np.ones(greys.shape), greys)\n",
    "# for i in tqdm(range(np.sum(mask))):\n",
    "    \n",
    "#     check_greens = np.all(mod_greens * solutions[mask] == solutions[mask], axis=(1,2))\n",
    "#     check_yellows = np.all(mod_yellows * solutions[mask] == solutions[mask], axis=(1,2))\n",
    "#     check_greys = np.all(mod_greys * solutions[mask] == solutions[mask], axis=(1,2))\n",
    "#     filtered = np.all(np.column_stack((check_greens, check_yellows, check_greys)), axis=1).sum()\n",
    "    \n",
    "#     ncands.append(filtered)\n",
    "\n",
    "# t1 = pd.DataFrame({'word': wordle.word, 'ncands': ncands})\n",
    "# print(t1.ncands.describe())\n",
    "\n",
    "# t2 = get_scores('pares', mask)\n",
    "# df2 = pd.DataFrame(t2, columns=['g', 'y', 'x'])\n",
    "# df2['score'] = df2.g * 2 + df2.y\n",
    "# df2['ncands'] = t1.ncands\n",
    "# t1.loc[t1.ncands.eq(t1.ncands.max())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779dfd9c-9d44-4f00-8831-e0f78388f1b2",
   "metadata": {},
   "source": [
    "## Vector Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a99dbf-e831-4453-9b17-5a547702d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vec(word):\n",
    "    mat = np.zeros((26, 5))\n",
    "    for i, l in enumerate(word):\n",
    "        mat[alpha_dict[l], i] = 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03a150ed-a3e3-46ec-972d-309de010dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(word, mask):\n",
    "    word_vec = init_vec(word)\n",
    "    solutions_masked = solutions[mask]\n",
    "    greens = solutions_masked * word_vec\n",
    "    yellows = word_vec * (\n",
    "        (solutions_masked.sum(axis=2) >= word_vec.sum(axis=1)) & \n",
    "        (word_vec.sum(axis=1) > 0)) \\\n",
    "        .reshape(np.sum(mask), 26, 1) - greens\n",
    "    greys = word_vec - greens - yellows\n",
    "    scores = np.array([np.sum(greens, axis=(1,2)), np.sum(yellows, axis=(1,2)), np.sum(greys, axis=(1,2))]).T\n",
    "    # scores = []\n",
    "    # for i in np.array(range(solutions.shape[0]))[mask]:\n",
    "    #     solution = solutions[i]\n",
    "    #     greens = solution * word_vec\n",
    "    #     yellows = word_vec * ((solution.sum(axis=1) >= word_vec.sum(axis=1)) & (word_vec.sum(axis=1) > 0)).reshape(26, 1) - greens\n",
    "    #     greys = word_vec - greens - yellows\n",
    "    #     scores.append((np.sum(greens), np.sum(yellows), np.sum(greys)))\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a647ba-3e57-404e-8c69-3918524d8509",
   "metadata": {},
   "source": [
    "## Global Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8c4ddd-0ff0-4313-8a35-90eb9eb87fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_letter_frequencies(wordset):\n",
    "    w = wordset.copy()\n",
    "    for letter in list('abcdefghijklmnopqrstuvwxyz'):\n",
    "        w[letter] = w.word.str.contains(letter).astype(int)\n",
    "    return w.iloc[:, 1:]\n",
    "\n",
    "def compute_score(x, freqs):\n",
    "    letters = set(x)\n",
    "    output = 0\n",
    "    for letter in letters:\n",
    "        output += freqs[letter]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "390fcb23-57d8-4953-a166-4ce9f5d1ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_freqs = compute_letter_frequencies(wordle).sum().to_dict()\n",
    "global_scores = wordle.word.apply(compute_score, freqs=global_freqs)\n",
    "global_scores = pd.DataFrame({'word': wordle.word, 'score': global_scores})\n",
    "global_scores = global_scores.merge(words_all[['word', 'word_freq', 'n_articles']], how='left', left_on='word', right_on='word')\n",
    "global_scores = global_scores.fillna(0).sort_values(['score', 'word_freq'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f05e4-71d8-4f01-91c5-0bd97b709323",
   "metadata": {},
   "source": [
    "## App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e4c1447-69d4-46f5-966b-52766537e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_scores(word, mask):\n",
    "    scores = get_scores(word, mask)\n",
    "    df_scores = pd.DataFrame(scores, columns=['g', 'y', 'x'])\n",
    "    df_scores['score'] = df_scores.g * 2 + df_scores.y\n",
    "    \n",
    "    return df_scores.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e9f6e76-b66d-404e-858f-33ce3aa0b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mask(input_word, feedback, wordset, mask):\n",
    "    newmask = mask.copy()\n",
    "    for i in range(5):\n",
    "        if feedback[i] == 'G':\n",
    "            newmask[~wordset.word.str[i].eq(input_word[i])] = False\n",
    "        elif feedback[i] == 'Y':\n",
    "            newmask[~(wordset.word.str.contains(input_word[i]) & wordset.word.apply(lambda x: x[i] != input_word[i]))] = False\n",
    "        elif feedback[i] == 'X':\n",
    "            newmask[wordset.word.str.contains(input_word[i])] = False\n",
    "            \n",
    "    return newmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bbfc7c7-7769-461f-8fca-9392bb5dc4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_n_filtered(input_word, solution):\n",
    "    feedback = get_feedback(input_word, solution)\n",
    "    candidates = filter_wordset(input_word, feedback, wordle)\n",
    "    return candidates.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aca58ebd-b0c9-4aa3-afeb-c72121ec868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_app(pre_load=None):\n",
    "    mask = np.array([True] * wordle.shape[0])\n",
    "    step = 1\n",
    "    w = wordle.copy()\n",
    "    res = pd.DataFrame([{'a': 1}, {'a': 1}])\n",
    "    tested_words = []\n",
    "    all_chars = []\n",
    "    \n",
    "    while res.shape[0] > 1:\n",
    "        print(f'[ ---- STEP {step} ----]')\n",
    "        if not (step == 1 and pre_load):\n",
    "            guess = input('Input a guess:')\n",
    "        else:\n",
    "            guess = pre_load\n",
    "        if guess.lower() in ['quit', 'q']:\n",
    "            return w, mask, res\n",
    "        tested_words.append(guess)\n",
    "        all_chars = all_chars + list(set(guess))\n",
    "        all_chars = list(set(all_chars))\n",
    "        \n",
    "        fb = input('Input feedback:')\n",
    "        if fb.lower() in ['quit', 'q']:\n",
    "            return w, mask, res\n",
    "        \n",
    "        mask = update_mask(guess, fb.upper(), wordle, mask)\n",
    "        w = filter_wordset(guess, fb.upper(), w)\n",
    "        \n",
    "        # Candidates\n",
    "        print(f'Found {w.shape[0]} candidates. Running analysis...')\n",
    "        new_scores = []\n",
    "        # new_ncands = []\n",
    "        for word in tqdm(w.word):\n",
    "            new_scores.append(get_final_scores(word, mask))\n",
    "            # temp_word = []\n",
    "            # for s in wordle_answers.word:\n",
    "            #     temp_word.append(compute_n_filtered(word, s))\n",
    "        \n",
    "        print(f'Suggestions for step {step + 1}:')\n",
    "        res = pd.DataFrame({'word': w.word, 'score': new_scores}) \\\n",
    "            .merge(words_all[['word', 'word_freq']], on='word', how='left') \\\n",
    "            .fillna(0)\n",
    "        display(res.sort_values(['score', 'word_freq'], ascending=False).head(10))\n",
    "        \n",
    "        # Filters\n",
    "        # if w.shape[0] > 10:\n",
    "        #     print(f'\\nLarge number of candidates found ({w.shape[0]}). We recommend filtering the candidates more:')\n",
    "        #     display(\n",
    "        #         global_scores.loc[global_scores.word.apply(lambda x: len(set(all_chars).intersection(set(list(x)))) < 1)] \\\n",
    "        #             .head(5)\n",
    "        #     )\n",
    "        if w.shape[0] <= 10:\n",
    "            print(f'Small number of candidates remaining ({w.shape[0]}). We recommend choosing the most popular option:')\n",
    "            display(res.sort_values(['word_freq', 'score'], ascending=False).head(5))\n",
    "        \n",
    "        # Check for repeats\n",
    "        if w.shape[0] <= 8 and w.shape[0] >= 3:\n",
    "            w_copy = res.sort_values(['word_freq', 'score'], ascending=False).copy()\n",
    "            # Extract letters\n",
    "            for i in range(5):\n",
    "                w_copy[f'p{i}'] = w_copy.word.str[i]\n",
    "            \n",
    "            # Count the number of unique columns\n",
    "            unique_mask = w_copy.iloc[:, -5:].nunique() > 1\n",
    "            \n",
    "            # If only 1, then recommend another word\n",
    "            if unique_mask.sum() == 1:\n",
    "                wc = wordle.copy()\n",
    "                total_letters = w_copy.shape[0]\n",
    "                wc['scores'] = 0\n",
    "                wc['counts'] = 0\n",
    "                for i, letter in enumerate(np.squeeze(w_copy[unique_mask.index[unique_mask]].values)):\n",
    "                    wc['scores'] = wc['scores'] + (total_letters - i) * wc.word.str.contains(letter).astype(int)\n",
    "                    wc['counts'] = wc['counts'] + wc.word.str.contains(letter).astype(int)\n",
    "                    \n",
    "                print(f'\\nWords with only one letter differential detected. Consider filtering:')\n",
    "                display(wc.loc[wc.counts.le(total_letters // 2 * 3)].sort_values('scores', ascending=False).head(5))\n",
    "\n",
    "                \n",
    "        step += 1\n",
    "        print()\n",
    "        \n",
    "    return w, mask, res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657b7fb-2308-4068-8d89-fe128dc60f52",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7de3bf1-8bca-42db-8281-9411acd00824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b36ad26c784d1aa1282caebe96437d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11553/687743871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mglobal_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_final_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Suggestions for step {step + 1}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mglobal_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word_freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'step' is not defined"
     ]
    }
   ],
   "source": [
    "global_list = []\n",
    "mask = [True] * wordle.shape[0]\n",
    "for word in tqdm(wordle.word):\n",
    "    global_list.append(get_final_scores(word, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e084064d-15c7-4c3f-b63c-4e217a3d4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = pd.DataFrame({'word': wordle.word, 'score': global_list}) \\\n",
    "    .merge(words_all[['word', 'word_freq']], on='word', how='left') \\\n",
    "    .fillna(0) \\\n",
    "    .sort_values(['score', 'word_freq'], ascending=False)\n",
    "dfg.to_csv('results/all_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a8cf649-b72e-4285-b10b-60f774344b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9100</th>\n",
       "      <td>tares</td>\n",
       "      <td>2.657570</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>lares</td>\n",
       "      <td>2.645467</td>\n",
       "      <td>296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>rales</td>\n",
       "      <td>2.622418</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>nares</td>\n",
       "      <td>2.600833</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7381</th>\n",
       "      <td>rates</td>\n",
       "      <td>2.598289</td>\n",
       "      <td>9301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>dares</td>\n",
       "      <td>2.590888</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>cares</td>\n",
       "      <td>2.580019</td>\n",
       "      <td>708.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>pares</td>\n",
       "      <td>2.572464</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>tales</td>\n",
       "      <td>2.569303</td>\n",
       "      <td>11745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>mares</td>\n",
       "      <td>2.558356</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     score  word_freq\n",
       "9100  tares  2.657570       12.0\n",
       "4998  lares  2.645467      296.0\n",
       "7336  rales  2.622418       28.0\n",
       "6063  nares  2.600833      253.0\n",
       "7381  rates  2.598289     9301.0\n",
       "2097  dares  2.590888      226.0\n",
       "1423  cares  2.580019      708.0\n",
       "6602  pares  2.572464      175.0\n",
       "9061  tales  2.569303    11745.0\n",
       "5513  mares  2.558356     1000.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576bba12-3f0e-4482-afcf-13d3c854b698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9d7ca-36d9-4efb-8ec5-631ab573bb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09783375-26cf-46fd-bce4-74a1a8b2835c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec7454-faf4-4cc7-ac3c-68b5dceeaf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ---- STEP 1 ----]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input feedback: xxxyy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 401 candidates. Running analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4f275f98dc49c58a11b6a28f5d2e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions for step 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>cider</td>\n",
       "      <td>4.309227</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>diner</td>\n",
       "      <td>4.301746</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dicer</td>\n",
       "      <td>4.279302</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tiler</td>\n",
       "      <td>4.274314</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dimer</td>\n",
       "      <td>4.264339</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>liter</td>\n",
       "      <td>4.259352</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>citer</td>\n",
       "      <td>4.254364</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bider</td>\n",
       "      <td>4.254364</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>diver</td>\n",
       "      <td>4.244389</td>\n",
       "      <td>3058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>niter</td>\n",
       "      <td>4.229426</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word     score  word_freq\n",
       "353  cider  4.309227     1093.0\n",
       "314  diner  4.301746     1125.0\n",
       "33   dicer  4.279302       62.0\n",
       "237  tiler  4.274314       37.0\n",
       "35   dimer  4.264339      390.0\n",
       "118  liter  4.259352      431.0\n",
       "17   citer  4.254364       10.0\n",
       "2    bider  4.254364        9.0\n",
       "328  diver  4.244389     3058.0\n",
       "145  niter  4.229426       49.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ ---- STEP 2 ----]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input a guess: cider\n",
      "Input feedback: xxxyy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 candidates. Running analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a8be740030444ebb887fbe3628b717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions for step 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ferny</td>\n",
       "      <td>4.93750</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>perky</td>\n",
       "      <td>4.90625</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pervy</td>\n",
       "      <td>4.78125</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nervy</td>\n",
       "      <td>4.75000</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>herby</td>\n",
       "      <td>4.68750</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ferly</td>\n",
       "      <td>4.68750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rebuy</td>\n",
       "      <td>4.65625</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>jerky</td>\n",
       "      <td>4.59375</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>reply</td>\n",
       "      <td>4.53125</td>\n",
       "      <td>1250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>germy</td>\n",
       "      <td>4.50000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word    score  word_freq\n",
       "3   ferny  4.93750       95.0\n",
       "26  perky  4.90625       95.0\n",
       "11  pervy  4.78125       15.0\n",
       "10  nervy  4.75000       23.0\n",
       "5   herby  4.68750       90.0\n",
       "2   ferly  4.68750        0.0\n",
       "15  rebuy  4.65625       12.0\n",
       "30  jerky  4.59375      236.0\n",
       "29  reply  4.53125     1250.0\n",
       "4   germy  4.50000        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ ---- STEP 3 ----]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input a guess: ferny\n",
      "Input feedback: xgyxx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 candidates. Running analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3dc5768a2b423aa36ccc193aa06c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions for step 4:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rebut</td>\n",
       "      <td>7.5</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rewth</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  score  word_freq\n",
       "1  rebut    7.5       53.0\n",
       "0  rewth    7.5        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small number of candidates remaining (2). We recommend choosing the most popular option:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rebut</td>\n",
       "      <td>7.5</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rewth</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  score  word_freq\n",
       "1  rebut    7.5       53.0\n",
       "0  rewth    7.5        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ ---- STEP 4 ----]\n"
     ]
    }
   ],
   "source": [
    "curr_wordset, curr_mask, curr_res = run_app('soare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a1b14-b0a3-487d-bf3f-6a44a4fe6a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3a9a1-9084-4b42-ac23-6a16d4922ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1a3ba-024e-48c2-a17e-348063330b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b9205-c29f-4517-8b60-ca1ccf2b0c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da9dfb-cd96-439b-884e-4be7edc4482f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
